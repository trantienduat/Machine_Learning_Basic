{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73b5fbc",
   "metadata": {},
   "source": [
    "# Medical Diagnosis Machine Learning Model\n",
    "\n",
    "This notebook builds a simple machine learning model to predict medical diagnoses using the medical training and test datasets.\n",
    "\n",
    "## Steps:\n",
    "1. Load and explore data\n",
    "2. Basic data preprocessing \n",
    "3. Split features and target\n",
    "4. Train a simple model\n",
    "5. Test the model\n",
    "6. Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2146f",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdcd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# Try importing optional libraries with availability checks\n",
    "try:\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "    from imblearn.under_sampling import TomekLinks\n",
    "    IMBLEARN_AVAILABLE = True\n",
    "    print(\"✅ imbalanced-learn is available\")\n",
    "except ImportError:\n",
    "    IMBLEARN_AVAILABLE = False\n",
    "    print(\"⚠️ imbalanced-learn not available - install with: pip install imbalanced-learn\")\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"✅ XGBoost is available\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"⚠️ XGBoost not available - install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    from scipy.stats import randint, uniform\n",
    "    SCIPY_AVAILABLE = True\n",
    "    print(\"✅ SciPy is available\")\n",
    "except ImportError:\n",
    "    SCIPY_AVAILABLE = False\n",
    "    print(\"⚠️ SciPy not available - install with: pip install scipy\")\n",
    "\n",
    "# Additional utility imports\n",
    "from collections import Counter\n",
    "\n",
    "# Configure warnings and display options\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.neighbors')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('default')\n",
    "\n",
    "# Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_data = pd.read_csv('medical_train_dataset.csv')\n",
    "test_data = pd.read_csv('medical_test_dataset.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(\"\\nTraining data columns:\")\n",
    "print(train_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402d548",
   "metadata": {},
   "source": [
    "## Step 2: Comprehensive Exploratory Data Analysis (EDA)\n",
    "\n",
    "We'll perform a thorough analysis of our medical dataset including:\n",
    "1. Data overview and basic information\n",
    "2. Missing value detection and visualization\n",
    "3. Numerical feature distributions and outlier detection\n",
    "4. Categorical feature analysis\n",
    "5. Target variable distribution analysis\n",
    "6. Correlation analysis between numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ccaf92",
   "metadata": {},
   "source": [
    "### 2.1 Data Overview and Basic Information\n",
    "\n",
    "Let's start by examining the basic structure of our dataset including:\n",
    "- Dataset dimensions (rows × columns)\n",
    "- Memory usage and data types\n",
    "- First few rows to understand the data structure\n",
    "- Statistical summary of numerical features\n",
    "- Column categorization by data type\n",
    "\n",
    "This foundational analysis helps us understand what we're working with before diving deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6514644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATA OVERVIEW AND INFO\n",
    "print(\"=\"*60)\n",
    "print(\"🔍 1. DATA OVERVIEW AND BASIC INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"📊 Training Dataset Overview:\")\n",
    "print(f\"Shape: {train_data.shape[0]} rows × {train_data.shape[1]} columns\")\n",
    "print(f\"Memory usage: {train_data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n📋 Column Information:\")\n",
    "print(train_data.info())\n",
    "\n",
    "print(\"\\n📝 First 5 rows of training data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\n📈 Basic Statistical Summary:\")\n",
    "print(train_data.describe())\n",
    "\n",
    "print(\"\\n🏷️ Data Types Summary:\")\n",
    "for dtype in train_data.dtypes.value_counts().index:\n",
    "    cols = train_data.select_dtypes(include=[dtype]).columns.tolist()\n",
    "    print(f\"{dtype}: {len(cols)} columns - {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d2b04",
   "metadata": {},
   "source": [
    "### 2.2 Missing Values Detection and Visualization\n",
    "\n",
    "Missing data can significantly impact our model's performance. In this section we will:\n",
    "- Calculate missing value counts and percentages for each column\n",
    "- Create visualizations to identify missing data patterns\n",
    "- Generate a heatmap to visualize missing value distribution across the dataset\n",
    "- Assess the overall data completeness\n",
    "\n",
    "Understanding missing data patterns helps us choose appropriate imputation strategies later in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MISSING VALUES DETECTION AND VISUALIZATION\n",
    "print(\"=\"*60)\n",
    "print(\"🕳️ 2. MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate missing values\n",
    "missing_data = train_data.isnull().sum()\n",
    "missing_percent = (missing_data / len(train_data)) * 100\n",
    "\n",
    "# Create missing values summary\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': missing_data.index,\n",
    "    'Missing_Count': missing_data.values,\n",
    "    'Missing_Percentage': missing_percent.values\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"📊 Missing Values Summary:\")\n",
    "print(missing_summary[missing_summary['Missing_Count'] > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Missing values count plot\n",
    "missing_cols = missing_summary[missing_summary['Missing_Count'] > 0]\n",
    "if len(missing_cols) > 0:\n",
    "    axes[0].bar(missing_cols['Column'], missing_cols['Missing_Count'])\n",
    "    axes[0].set_title('Missing Values Count by Column')\n",
    "    axes[0].set_xlabel('Columns')\n",
    "    axes[0].set_ylabel('Missing Count')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'No Missing Values Found!', \n",
    "                ha='center', va='center', transform=axes[0].transAxes, fontsize=14)\n",
    "    axes[0].set_title('Missing Values Count')\n",
    "\n",
    "# Missing values heatmap\n",
    "sns.heatmap(train_data.isnull(), yticklabels=False, cbar=True, cmap='viridis', ax=axes[1])\n",
    "axes[1].set_title('Missing Values Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Total missing values: {missing_data.sum()}\")\n",
    "print(f\"📊 Percentage of complete records: {(1 - train_data.isnull().any(axis=1).sum()/len(train_data))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a699a7",
   "metadata": {},
   "source": [
    "### 2.3 Numerical Features Distribution Analysis\n",
    "\n",
    "Numerical features often contain the most predictive power in medical datasets. We'll analyze:\n",
    "- **Distribution Patterns**: Histograms with mean/median markers to understand data spread\n",
    "- **Statistical Properties**: Mean, median, standard deviation, and skewness for each feature\n",
    "- **Outlier Detection**: Box plots with IQR-based outlier identification\n",
    "- **Data Quality**: Identify potential data entry errors or unusual patterns\n",
    "\n",
    "This analysis helps us understand feature characteristics and decide on appropriate scaling and transformation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. NUMERICAL FEATURES ANALYSIS\n",
    "print(\"=\"*60)\n",
    "print(\"📊 3. NUMERICAL FEATURES DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"📈 Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "\n",
    "# Create subplots for histograms\n",
    "n_cols = 3\n",
    "n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "print(\"\\n📊 Distribution Statistics:\")\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    if i < len(axes):\n",
    "        # Histogram with KDE\n",
    "        axes[i].hist(train_data[col].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        \n",
    "        # Add mean and median lines\n",
    "        mean_val = train_data[col].mean()\n",
    "        median_val = train_data[col].median()\n",
    "        axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "        axes[i].axvline(median_val, color='green', linestyle='--', label=f'Median: {median_val:.2f}')\n",
    "        axes[i].legend()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"  {col}:\")\n",
    "        print(f\"    Mean: {mean_val:.2f}, Median: {median_val:.2f}\")\n",
    "        print(f\"    Std: {train_data[col].std():.2f}, Skewness: {train_data[col].skew():.2f}\")\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(len(numerical_cols), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Box plots for outlier detection\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "print(\"\\n🎯 Outlier Detection (using IQR method):\")\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    if i < len(axes):\n",
    "        # Box plot\n",
    "        box_plot = axes[i].boxplot(train_data[col].dropna(), patch_artist=True)\n",
    "        box_plot['boxes'][0].set_facecolor('lightblue')\n",
    "        axes[i].set_title(f'Box Plot: {col}')\n",
    "        axes[i].set_ylabel(col)\n",
    "        \n",
    "        # Calculate outliers using IQR method\n",
    "        Q1 = train_data[col].quantile(0.25)\n",
    "        Q3 = train_data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = train_data[(train_data[col] < lower_bound) | (train_data[col] > upper_bound)][col]\n",
    "        print(f\"  {col}: {len(outliers)} outliers ({len(outliers)/len(train_data)*100:.1f}%)\")\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(len(numerical_cols), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068e1ae",
   "metadata": {},
   "source": [
    "### 2.4 Categorical Features Analysis\n",
    "\n",
    "Categorical variables provide important contextual information in medical diagnosis. We'll examine:\n",
    "- **Unique Value Counts**: Number of distinct categories per feature\n",
    "- **Frequency Distribution**: Most and least common categories\n",
    "- **Value Balance**: Check for heavily skewed categorical distributions\n",
    "- **Visualization**: Bar plots showing the distribution of each categorical feature\n",
    "\n",
    "Understanding categorical feature distributions helps us choose appropriate encoding strategies and identify potential data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CATEGORICAL FEATURES ANALYSIS\n",
    "print(\"=\"*60)\n",
    "print(\"🏷️ 4. CATEGORICAL FEATURES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"📝 Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "print(\"\\n📊 Categorical Features Summary:\")\n",
    "for col in categorical_cols:\n",
    "    unique_count = train_data[col].nunique()\n",
    "    most_frequent = train_data[col].mode()[0] if len(train_data[col].mode()) > 0 else 'N/A'\n",
    "    print(f\"  {col}:\")\n",
    "    print(f\"    Unique values: {unique_count}\")\n",
    "    print(f\"    Most frequent: {most_frequent}\")\n",
    "    print(f\"    Value counts: {train_data[col].value_counts().to_dict()}\")\n",
    "\n",
    "# Visualize categorical features\n",
    "if len(categorical_cols) > 0:\n",
    "    n_cols = 2\n",
    "    n_rows = (len(categorical_cols) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "    \n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        if i < len(axes):\n",
    "            value_counts = train_data[col].value_counts()\n",
    "            \n",
    "            # Bar plot\n",
    "            axes[i].bar(range(len(value_counts)), value_counts.values, color='lightcoral')\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Count')\n",
    "            axes[i].set_xticks(range(len(value_counts)))\n",
    "            axes[i].set_xticklabels(value_counts.index, rotation=45)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for j, v in enumerate(value_counts.values):\n",
    "                axes[i].text(j, v + max(value_counts.values)*0.01, str(v), \n",
    "                           ha='center', va='bottom')\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for i in range(len(categorical_cols), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No categorical columns found for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414504c",
   "metadata": {},
   "source": [
    "### 2.5 Target Variable Distribution Analysis\n",
    "\n",
    "The target variable (diagnosis) is the heart of our prediction task. We'll analyze:\n",
    "- **Class Distribution**: Count and percentage of each diagnosis category\n",
    "- **Class Balance**: Identify potential class imbalance issues\n",
    "- **Visual Analysis**: Count plots and pie charts for easy interpretation\n",
    "- **Imbalance Assessment**: Calculate class ratios to determine if special handling is needed\n",
    "\n",
    "Understanding target distribution is crucial for model selection, evaluation metrics, and potential sampling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47fe79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. TARGET VARIABLE ANALYSIS\n",
    "print(\"=\"*60)\n",
    "print(\"🎯 5. TARGET VARIABLE DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Focus on the main target variable: diagnosis\n",
    "target_col = 'diagnosis'\n",
    "\n",
    "if target_col in train_data.columns:\n",
    "    print(f\"🏷️ Analyzing target variable: '{target_col}'\")\n",
    "else:\n",
    "    print(f\"⚠️ Target column '{target_col}' not found in dataset!\")\n",
    "    print(f\"Available columns: {train_data.columns.tolist()}\")\n",
    "\n",
    "if target_col in train_data.columns:\n",
    "    print(f\"\\n📊 Analysis for '{target_col}':\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    value_counts = train_data[target_col].value_counts()\n",
    "    value_percentages = train_data[target_col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(f\"  Unique classes: {train_data[target_col].nunique()}\")\n",
    "    print(f\"  Value counts:\")\n",
    "    for val, count in value_counts.items():\n",
    "        percentage = value_percentages[val]\n",
    "        print(f\"    {val}: {count} samples ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Count plot\n",
    "    axes[0].bar(range(len(value_counts)), value_counts.values, color='lightgreen')\n",
    "    axes[0].set_title(f'Distribution of {target_col}')\n",
    "    axes[0].set_xlabel(target_col)\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].set_xticks(range(len(value_counts)))\n",
    "    axes[0].set_xticklabels(value_counts.index, rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(value_counts.values):\n",
    "        axes[0].text(i, v + max(value_counts.values)*0.01, \n",
    "                    f'{v}\\n({value_percentages.iloc[i]:.1f}%)', \n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%', \n",
    "               colors=['lightgreen', 'lightcoral', 'lightblue', 'lightyellow'][:len(value_counts)])\n",
    "    axes[1].set_title(f'Percentage Distribution of {target_col}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for class imbalance\n",
    "    max_class_ratio = value_percentages.max() / value_percentages.min()\n",
    "    print(f\"  📈 Class imbalance ratio: {max_class_ratio:.2f}\")\n",
    "    if max_class_ratio > 3:\n",
    "        print(f\"  ⚠️ Warning: Significant class imbalance detected!\")\n",
    "    else:\n",
    "        print(f\"  ✅ Classes are relatively balanced.\")\n",
    "    \n",
    "    # Additional insights about diagnosis categories\n",
    "    print(f\"\\n🔍 Additional Insights:\")\n",
    "    print(f\"  Most common diagnosis: {value_counts.index[0]} ({value_percentages.iloc[0]:.1f}%)\")\n",
    "    print(f\"  Least common diagnosis: {value_counts.index[-1]} ({value_percentages.iloc[-1]:.1f}%)\")\n",
    "    print(f\"  Class balance quality: {'Good' if max_class_ratio < 2 else 'Moderate' if max_class_ratio < 3 else 'Poor'}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot perform target variable analysis - target column not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CORRELATION ANALYSIS BETWEEN NUMERICAL FEATURES\n",
    "print(\"=\"*60)\n",
    "print(\"🔗 6. CORRELATION ANALYSIS BETWEEN NUMERICAL FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate correlation matrix for numerical features only\n",
    "numerical_data = train_data.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "print(f\"📊 Correlation matrix shape: {correlation_matrix.shape}\")\n",
    "print(f\"📈 Numerical features included: {list(correlation_matrix.columns)}\")\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "sns.heatmap(correlation_matrix, \n",
    "           annot=True, \n",
    "           cmap='RdBu_r', \n",
    "           center=0,\n",
    "           square=True,\n",
    "           mask=mask,\n",
    "           cbar_kws={\"shrink\": .8},\n",
    "           fmt='.2f')\n",
    "plt.title('Correlation Heatmap - Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated pairs\n",
    "print(\"\\n🔍 Highly Correlated Feature Pairs (|correlation| > 0.7):\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.7:\n",
    "            feature1 = correlation_matrix.columns[i]\n",
    "            feature2 = correlation_matrix.columns[j]\n",
    "            high_corr_pairs.append((feature1, feature2, corr_value))\n",
    "            print(f\"  {feature1} ↔ {feature2}: {corr_value:.3f}\")\n",
    "\n",
    "if len(high_corr_pairs) == 0:\n",
    "    print(\"  ✅ No highly correlated pairs found (threshold: |r| > 0.7)\")\n",
    "\n",
    "# Show strongest positive and negative correlations\n",
    "print(f\"\\n📈 Strongest Positive Correlations:\")\n",
    "positive_corrs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if corr_value > 0:\n",
    "            positive_corrs.append((correlation_matrix.columns[i], \n",
    "                                 correlation_matrix.columns[j], corr_value))\n",
    "\n",
    "positive_corrs.sort(key=lambda x: x[2], reverse=True)\n",
    "for feat1, feat2, corr in positive_corrs[:5]:\n",
    "    print(f\"  {feat1} ↔ {feat2}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\n📉 Strongest Negative Correlations:\")\n",
    "negative_corrs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if corr_value < 0:\n",
    "            negative_corrs.append((correlation_matrix.columns[i], \n",
    "                                 correlation_matrix.columns[j], corr_value))\n",
    "\n",
    "negative_corrs.sort(key=lambda x: x[2])\n",
    "for feat1, feat2, corr in negative_corrs[:5]:\n",
    "    print(f\"  {feat1} ↔ {feat2}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 COMPREHENSIVE EDA COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(\"✅ Data overview and basic info analyzed\")\n",
    "print(\"✅ Missing values detected and visualized\") \n",
    "print(\"✅ Numerical feature distributions and outliers analyzed\")\n",
    "print(\"✅ Categorical features summarized and plotted\")\n",
    "print(\"✅ Target variable distribution analyzed\")\n",
    "print(\"✅ Correlation patterns between numerical features identified\")\n",
    "print(\"🚀 Ready for data preprocessing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc9b17",
   "metadata": {},
   "source": [
    "## Step 3: Comprehensive Data Preprocessing\n",
    "\n",
    "We'll implement a robust preprocessing pipeline with strict train/test separation to ensure data integrity and prevent data leakage:\n",
    "1. Missing value imputation using KNN-based approach\n",
    "2. Categorical variable encoding with proper handling of unseen categories\n",
    "3. Numerical feature scaling and standardization\n",
    "4. Class balancing to address target variable imbalance\n",
    "5. Data export and pipeline component preservation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff89e86",
   "metadata": {},
   "source": [
    "### 3.1 Missing Value Imputation\n",
    "\n",
    "For handling missing values in our dataset, we'll implement **K-Nearest Neighbors (KNN) imputation**, which is more sophisticated than simple statistical measures like median or mean imputation.\n",
    "\n",
    "**KNN Imputation Approach:**\n",
    "- **Method**: Uses the K nearest neighbors to estimate missing values based on feature similarity\n",
    "- **Advantages**: \n",
    "  - Preserves relationships between features\n",
    "  - More accurate than univariate methods (median/mean)\n",
    "  - Considers multivariate patterns in the data\n",
    "- **Parameters**: We'll use `n_neighbors=5` as a balanced choice between accuracy and computational efficiency\n",
    "- **Robustness**: Handles missing values by finding similar patients based on available features\n",
    "\n",
    "**Implementation Strategy:**\n",
    "1. **Training Phase**: Fit KNN imputer only on training data to prevent data leakage\n",
    "2. **Application**: Apply the same imputation model to both training and test sets\n",
    "3. **Validation**: Verify complete removal of missing values and track imputation statistics\n",
    "4. **Numerical Stability**: Suppress harmless sklearn numerical warnings for cleaner output\n",
    "\n",
    "**Technical Notes:**\n",
    "- The `nan_euclidean` metric is specifically designed for datasets with missing values\n",
    "- Warnings about matrix operations are common with KNN and don't affect results\n",
    "- We suppress these warnings for cleaner output while preserving all functionality\n",
    "\n",
    "This approach is particularly suitable for medical data where patient characteristics are often correlated, making neighbor-based imputation more meaningful than simple statistical substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb38fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 MISSING VALUE IMPUTATION\n",
    "print(\"=\" * 60)\n",
    "print(\"📊 3.1 MISSING VALUE IMPUTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress numerical warnings from KNN computation\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='sklearn.utils.extmath')\n",
    "\n",
    "print(\"🔄 Starting KNN-based missing value imputation...\")\n",
    "\n",
    "# Make copies of the data for processing\n",
    "train_processed = train_data.copy()\n",
    "test_processed = test_data.copy()\n",
    "\n",
    "# Check missing values before imputation\n",
    "missing_before = train_processed[numerical_cols].isnull().sum()\n",
    "print(\"\\n📊 Missing values before imputation:\")\n",
    "for col in numerical_cols:\n",
    "    if col in train_processed.columns:\n",
    "        missing_count = missing_before[col] if col in missing_before.index else 0\n",
    "        print(f\"  {col}: {missing_count} missing values\")\n",
    "\n",
    "# Initialize KNN Imputer with robust parameters\n",
    "# Using n_neighbors=5 as a balanced choice for medical data\n",
    "knn_imputer = KNNImputer(\n",
    "    n_neighbors=5, \n",
    "    weights='uniform',\n",
    "    metric='nan_euclidean',  # Explicitly set for handling NaN values\n",
    "    copy=True  # Ensure we don't modify original data\n",
    ")\n",
    "\n",
    "print(f\"\\n🔧 Configuring KNN Imputer:\")\n",
    "print(f\"  - n_neighbors: 5 (balanced choice for medical data)\")\n",
    "print(f\"  - weights: uniform (equal weight to all neighbors)\")\n",
    "print(f\"  - metric: nan_euclidean (robust for missing values)\")\n",
    "print(f\"  - copy: True (preserve original data)\")\n",
    "\n",
    "# Fit the imputer on training data only (prevent data leakage)\n",
    "print(f\"\\n🎯 Fitting KNN imputer on training data...\")\n",
    "try:\n",
    "    knn_imputer.fit(train_processed[numerical_cols])\n",
    "    print(f\"  ✅ KNN imputer fitted successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"  ⚠️ Warning during fitting: {str(e)}\")\n",
    "\n",
    "# Apply imputation to both training and test sets\n",
    "print(f\"📈 Applying KNN imputation...\")\n",
    "\n",
    "try:\n",
    "    # Transform training data\n",
    "    train_imputed = knn_imputer.transform(train_processed[numerical_cols])\n",
    "    train_processed[numerical_cols] = train_imputed\n",
    "    \n",
    "    # Transform test data\n",
    "    test_imputed = knn_imputer.transform(test_processed[numerical_cols])\n",
    "    test_processed[numerical_cols] = test_imputed\n",
    "    \n",
    "    print(f\"  ✅ KNN imputation applied successfully to both datasets\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ⚠️ Warning during transformation: {str(e)}\")\n",
    "    print(f\"  🔄 Continuing with available imputed data...\")\n",
    "\n",
    "# Verify imputation results\n",
    "missing_after = train_processed[numerical_cols].isnull().sum()\n",
    "missing_after_test = test_processed[numerical_cols].isnull().sum()\n",
    "\n",
    "print(f\"\\n📊 Imputation Results:\")\n",
    "for col in numerical_cols:\n",
    "    if col in train_processed.columns:\n",
    "        missing_train = missing_before[col] if col in missing_before.index else 0\n",
    "        missing_train_after = missing_after[col] if col in missing_after.index else 0\n",
    "        missing_test_after = missing_after_test[col] if col in missing_after_test.index else 0\n",
    "        \n",
    "        if missing_train > 0:\n",
    "            # Calculate some statistics about the imputed values\n",
    "            mean_original = train_data[col].dropna().mean()\n",
    "            mean_imputed = train_processed[col].mean()\n",
    "            print(f\"  ✅ {col}: imputed {missing_train} training values\")\n",
    "            print(f\"     → Original mean: {mean_original:.2f}, Post-imputation mean: {mean_imputed:.2f}\")\n",
    "        else:\n",
    "            print(f\"  ✅ {col}: no missing values (no imputation needed)\")\n",
    "\n",
    "print(f\"\\n📊 Missing values after KNN imputation:\")\n",
    "total_missing_train = missing_after.sum()\n",
    "total_missing_test = missing_after_test.sum()\n",
    "print(f\"  Training set: {total_missing_train} missing values remaining\")\n",
    "print(f\"  Test set: {total_missing_test} missing values remaining\")\n",
    "\n",
    "if total_missing_train == 0 and total_missing_test == 0:\n",
    "    print(f\"  ✅ All missing values successfully imputed!\")\n",
    "else:\n",
    "    print(f\"  ⚠️ Warning: Some missing values remain!\")\n",
    "\n",
    "# Store the fitted imputer for future use\n",
    "imputation_model = knn_imputer\n",
    "\n",
    "# Re-enable warnings\n",
    "warnings.resetwarnings()\n",
    "\n",
    "print(f\"\\n💾 KNN Imputer model saved for consistent preprocessing\")\n",
    "print(f\"✅ KNN-based missing value imputation completed!\")\n",
    "print(f\"📝 Note: Numerical warnings from sklearn have been suppressed for cleaner output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b253f",
   "metadata": {},
   "source": [
    "### 3.2 Categorical Variable Encoding\n",
    "\n",
    "Machine learning algorithms require numerical inputs, so we must encode categorical variables properly:\n",
    "- **LabelEncoder Training**: Fit encoders only on training data to learn category mappings\n",
    "- **Consistent Encoding**: Apply the same encoding scheme to both training and test data\n",
    "- **Unseen Category Handling**: Gracefully handle categories in test data that weren't in training\n",
    "- **Reproducibility**: Save all encoders for future use with new data\n",
    "\n",
    "This ensures consistent categorical representation across all datasets while preventing data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30db4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 CATEGORICAL VARIABLE ENCODING\n",
    "print(\"=\"*60)\n",
    "print(\"🏷️ 3.2 CATEGORICAL VARIABLE ENCODING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define categorical columns to encode\n",
    "categorical_columns = ['gender', 'smoking_status', 'exercise_level', 'family_history']\n",
    "label_encoders = {}\n",
    "\n",
    "print(\"🔄 Starting categorical variable encoding...\")\n",
    "\n",
    "# Check which categorical columns exist\n",
    "available_categorical = [col for col in categorical_columns if col in train_processed.columns]\n",
    "print(f\"📝 Available categorical columns: {available_categorical}\")\n",
    "\n",
    "for col in available_categorical:\n",
    "    print(f\"\\n🏷️ Processing column: {col}\")\n",
    "    \n",
    "    # Show original values\n",
    "    unique_values = train_processed[col].unique()\n",
    "    print(f\"  Original unique values: {unique_values}\")\n",
    "    \n",
    "    # Fit encoder on training data only\n",
    "    le = LabelEncoder()\n",
    "    train_processed[col] = le.fit_transform(train_processed[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    \n",
    "    # Show encoded mapping\n",
    "    print(f\"  Encoded mapping: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "    \n",
    "    if col in test_processed.columns:\n",
    "        # Handle unseen categories in test data\n",
    "        test_categories = test_processed[col].astype(str)\n",
    "        test_encoded = []\n",
    "        unseen_categories = set()\n",
    "        \n",
    "        for category in test_categories:\n",
    "            if category in le.classes_:\n",
    "                test_encoded.append(le.transform([category])[0])\n",
    "            else:\n",
    "                # Use the most frequent category for unseen values\n",
    "                test_encoded.append(le.transform([le.classes_[0]])[0])\n",
    "                unseen_categories.add(category)\n",
    "        \n",
    "        test_processed[col] = test_encoded\n",
    "        \n",
    "        if unseen_categories:\n",
    "            print(f\"  ⚠️ Unseen categories in test data: {unseen_categories}\")\n",
    "            print(f\"     Mapped to default category: {le.classes_[0]} (encoded as 0)\")\n",
    "        \n",
    "        print(f\"  ✅ {col}: encoded with {len(le.classes_)} categories\")\n",
    "    else:\n",
    "        print(f\"  ✅ {col}: encoded with {len(le.classes_)} categories (training only)\")\n",
    "\n",
    "print(f\"\\n📊 Encoding Summary:\")\n",
    "print(f\"  Total categorical columns processed: {len(available_categorical)}\")\n",
    "print(f\"  Total encoders created: {len(label_encoders)}\")\n",
    "\n",
    "print(\"✅ Categorical variable encoding completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d215a",
   "metadata": {},
   "source": [
    "### 3.3 Numerical Feature Scaling and Standardization\n",
    "\n",
    "Different numerical features often have vastly different scales, which can bias machine learning algorithms. We'll standardize features:\n",
    "- **StandardScaler Training**: Compute mean and standard deviation from training data only\n",
    "- **Z-Score Normalization**: Transform features to have mean≈0 and std≈1\n",
    "- **Consistent Scaling**: Apply same scaling parameters to both training and test data\n",
    "- **Algorithm Optimization**: Ensure features contribute equally to distance-based algorithms\n",
    "\n",
    "This standardization improves model convergence and prevents features with larger scales from dominating the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 NUMERICAL FEATURE SCALING AND STANDARDIZATION\n",
    "print(\"=\"*60)\n",
    "print(\"📏 3.3 NUMERICAL FEATURE SCALING AND STANDARDIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "print(\"🔄 Starting numerical feature scaling...\")\n",
    "\n",
    "# Identify numerical columns for scaling (all numerical columns)\n",
    "numerical_features_for_scaling = [col for col in numerical_cols if col in train_processed.columns]\n",
    "print(f\"📈 Features to be scaled: {numerical_features_for_scaling}\")\n",
    "\n",
    "# Show statistics before scaling\n",
    "print(f\"\\n📊 Statistics before scaling (training data):\")\n",
    "for col in numerical_features_for_scaling[:3]:  # Show first 3 for brevity\n",
    "    mean_val = train_processed[col].mean()\n",
    "    std_val = train_processed[col].std()\n",
    "    print(f\"  {col}: mean={mean_val:.2f}, std={std_val:.2f}\")\n",
    "\n",
    "# Fit scaler on training data only\n",
    "print(\"\\n🎯 Fitting scaler on training data...\")\n",
    "scaler.fit(train_processed[numerical_features_for_scaling])\n",
    "\n",
    "# Apply scaling to both train and test data\n",
    "train_processed[numerical_features_for_scaling] = scaler.transform(train_processed[numerical_features_for_scaling])\n",
    "test_processed[numerical_features_for_scaling] = scaler.transform(test_processed[numerical_features_for_scaling])\n",
    "\n",
    "print(f\"✅ Scaled {len(numerical_features_for_scaling)} numerical features\")\n",
    "\n",
    "# Show statistics after scaling\n",
    "print(f\"\\n📊 Statistics after scaling (training data):\")\n",
    "for col in numerical_features_for_scaling[:3]:  # Show first 3 for brevity\n",
    "    mean_val = train_processed[col].mean()\n",
    "    std_val = train_processed[col].std()\n",
    "    print(f\"  {col}: mean={mean_val:.3f}, std={std_val:.3f}\")\n",
    "\n",
    "# Show scaler parameters\n",
    "print(f\"\\n🔧 Scaler parameters (computed from training data):\")\n",
    "print(f\"  Feature means: {scaler.mean_[:3]}... (showing first 3)\")\n",
    "print(f\"  Feature scales: {scaler.scale_[:3]}... (showing first 3)\")\n",
    "\n",
    "print(\"✅ Numerical feature scaling completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487f255",
   "metadata": {},
   "source": [
    "### 3.4 Advanced Feature Engineering for Medical Diagnosis\n",
    "\n",
    "Feature engineering is crucial for improving model performance by creating meaningful representations of domain knowledge. For medical diagnosis, we'll create features that capture:\n",
    "\n",
    "**Clinical Domain Features:**\n",
    "- **BMI categorization**: Standard medical BMI categories for health risk assessment\n",
    "- **Age grouping**: Life stage categories relevant to disease risk patterns\n",
    "- **Clinical thresholds**: Binary indicators for high blood pressure and medication burden\n",
    "- **Log transformations**: Handle skewed distributions in medical measurements\n",
    "\n",
    "**Advanced Interaction Features:**\n",
    "- **Age-BMI interaction**: Combined effect of age and weight on health outcomes\n",
    "- **Cholesterol-smoking interaction**: Multiplicative risk factor for cardiovascular disease\n",
    "- **One-hot encoding**: Proper categorical representation for machine learning algorithms\n",
    "\n",
    "This approach leverages medical domain knowledge to create features that are both interpretable and predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a96b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 ADVANCED FEATURE ENGINEERING FOR MEDICAL DIAGNOSIS\n",
    "print(\"=\" * 60)\n",
    "print(\"🔧 3.4 ADVANCED FEATURE ENGINEERING FOR MEDICAL DIAGNOSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"🔄 Starting comprehensive feature engineering...\")\n",
    "\n",
    "# Create copies for feature engineering\n",
    "train_engineered = train_processed.copy()\n",
    "test_engineered = test_processed.copy()\n",
    "\n",
    "# Track new features for documentation\n",
    "engineered_features = []\n",
    "feature_descriptions = {}\n",
    "\n",
    "print(\"\\n📊 1. CREATING BMI GROUPS (Clinical Categories)\")\n",
    "# 1. Create BMI groups using standard medical categories\n",
    "def create_bmi_groups(bmi):\n",
    "    \"\"\"Create BMI categories based on medical standards\"\"\"\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif 18.5 <= bmi < 25.0:\n",
    "        return 'Normal'\n",
    "    elif 25.0 <= bmi < 30.0:\n",
    "        return 'Overweight'\n",
    "    else:\n",
    "        return 'Obese'\n",
    "\n",
    "# Assuming 'bmi' column exists\n",
    "if 'bmi' in train_engineered.columns:\n",
    "    train_engineered['bmi_group'] = train_engineered['bmi'].apply(create_bmi_groups)\n",
    "    test_engineered['bmi_group'] = test_engineered['bmi'].apply(create_bmi_groups)\n",
    "    \n",
    "    # Show distribution\n",
    "    print(f\"  BMI Groups Distribution (Training):\")\n",
    "    bmi_dist = train_engineered['bmi_group'].value_counts()\n",
    "    for group, count in bmi_dist.items():\n",
    "        pct = (count / len(train_engineered)) * 100\n",
    "        print(f\"    {group}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    engineered_features.append('bmi_group')\n",
    "    feature_descriptions['bmi_group'] = \"BMI categories: Underweight (<18.5), Normal (18.5-24.9), Overweight (25-29.9), Obese (>=30)\"\n",
    "else:\n",
    "    print(\"  ⚠️ BMI column not found - skipping BMI group creation\")\n",
    "\n",
    "print(\"\\n👴 2. CREATING AGE GROUPS (Life Stage Categories)\")\n",
    "# 2. Create age groups\n",
    "def create_age_groups(age):\n",
    "    \"\"\"Create age categories based on life stages\"\"\"\n",
    "    if age < 40:\n",
    "        return '<40'\n",
    "    elif 40 <= age < 60:\n",
    "        return '40-59'\n",
    "    else:\n",
    "        return '60+'\n",
    "\n",
    "# Assuming 'age' column exists\n",
    "if 'age' in train_engineered.columns:\n",
    "    train_engineered['age_group'] = train_engineered['age'].apply(create_age_groups)\n",
    "    test_engineered['age_group'] = test_engineered['age'].apply(create_age_groups)\n",
    "    \n",
    "    # Show distribution\n",
    "    print(f\"  Age Groups Distribution (Training):\")\n",
    "    age_dist = train_engineered['age_group'].value_counts()\n",
    "    for group, count in age_dist.items():\n",
    "        pct = (count / len(train_engineered)) * 100\n",
    "        print(f\"    {group}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    engineered_features.append('age_group')\n",
    "    feature_descriptions['age_group'] = \"Age categories: <40, 40-59, 60+\"\n",
    "else:\n",
    "    print(\"  ⚠️ Age column not found - skipping age group creation\")\n",
    "\n",
    "print(\"\\n🩺 3. CREATING HIGH BLOOD PRESSURE INDICATOR\")\n",
    "# 3. Create high blood pressure binary feature\n",
    "bp_cols_found = []\n",
    "if 'systolic_bp' in train_engineered.columns:\n",
    "    bp_cols_found.append('systolic_bp')\n",
    "if 'diastolic_bp' in train_engineered.columns:\n",
    "    bp_cols_found.append('diastolic_bp')\n",
    "\n",
    "if len(bp_cols_found) == 2:\n",
    "    # High BP: systolic >= 140 OR diastolic >= 90\n",
    "    train_engineered['high_bp'] = ((train_engineered['systolic_bp'] >= 140) | \n",
    "                                   (train_engineered['diastolic_bp'] >= 90)).astype(int)\n",
    "    test_engineered['high_bp'] = ((test_engineered['systolic_bp'] >= 140) | \n",
    "                                  (test_engineered['diastolic_bp'] >= 90)).astype(int)\n",
    "    \n",
    "    # Show distribution\n",
    "    high_bp_train_pct = (train_engineered['high_bp'].sum() / len(train_engineered)) * 100\n",
    "    print(f\"  High BP Distribution (Training): {train_engineered['high_bp'].sum()} patients ({high_bp_train_pct:.1f}%)\")\n",
    "    \n",
    "    engineered_features.append('high_bp')\n",
    "    feature_descriptions['high_bp'] = \"Binary indicator: 1 if systolic_bp >= 140 or diastolic_bp >= 90, else 0\"\n",
    "else:\n",
    "    print(f\"  ⚠️ Blood pressure columns not found (found: {bp_cols_found}) - skipping high BP feature\")\n",
    "\n",
    "print(\"\\n💊 4. CREATING HIGH MEDICATION COUNT INDICATOR\")\n",
    "# 4. Create high medication count binary feature\n",
    "if 'medication_count' in train_engineered.columns:\n",
    "    train_engineered['many_meds'] = (train_engineered['medication_count'] > 5).astype(int)\n",
    "    test_engineered['many_meds'] = (test_engineered['medication_count'] > 5).astype(int)\n",
    "    \n",
    "    # Show distribution\n",
    "    high_med_train_pct = (train_engineered['many_meds'].sum() / len(train_engineered)) * 100\n",
    "    print(f\"  High Medication Count Distribution (Training): {train_engineered['many_meds'].sum()} patients ({high_med_train_pct:.1f}%)\")\n",
    "    \n",
    "    engineered_features.append('many_meds')\n",
    "    feature_descriptions['many_meds'] = \"Binary indicator: 1 if medication_count > 5, else 0\"\n",
    "else:\n",
    "    print(\"  ⚠️ Medication count column not found - skipping high medication feature\")\n",
    "\n",
    "print(\"\\n📊 5. CREATING LOG-TRANSFORMED FEATURES\")\n",
    "# 5. Log-transform skewed numerical features with robust handling\n",
    "log_transform_cols = ['blood_glucose', 'medication_count']\n",
    "for col in log_transform_cols:\n",
    "    if col in train_engineered.columns:\n",
    "        # Check for negative values or NaNs before transformation\n",
    "        train_negative = (train_engineered[col] < 0).sum()\n",
    "        test_negative = (test_engineered[col] < 0).sum()\n",
    "        train_nan = train_engineered[col].isna().sum()\n",
    "        test_nan = test_engineered[col].isna().sum()\n",
    "        \n",
    "        if train_negative > 0 or test_negative > 0:\n",
    "            print(f\"  ⚠️ {col}: Found {train_negative} negative values in train, {test_negative} in test\")\n",
    "            # Clip negative values to 0 for log transformation\n",
    "            train_clipped = train_engineered[col].clip(lower=0)\n",
    "            test_clipped = test_engineered[col].clip(lower=0)\n",
    "            print(f\"    → Clipped negative values to 0 for log transformation\")\n",
    "        else:\n",
    "            train_clipped = train_engineered[col]\n",
    "            test_clipped = test_engineered[col]\n",
    "            \n",
    "        if train_nan > 0 or test_nan > 0:\n",
    "            print(f\"  ⚠️ {col}: Found {train_nan} NaN values in train, {test_nan} in test\")\n",
    "            print(f\"    → NaN values will be preserved in log transformation\")\n",
    "        \n",
    "        # Apply log1p transformation with proper handling\n",
    "        with np.errstate(invalid='ignore'):  # Suppress warnings for this block\n",
    "            train_engineered[f'{col}_log'] = np.log1p(train_clipped)\n",
    "            test_engineered[f'{col}_log'] = np.log1p(test_clipped)\n",
    "        \n",
    "        # Show transformation statistics\n",
    "        original_skew = train_engineered[col].skew()\n",
    "        log_skew = train_engineered[f'{col}_log'].skew()\n",
    "        print(f\"  ✅ {col}: Skewness {original_skew:.3f} → {log_skew:.3f} (log-transformed)\")\n",
    "        \n",
    "        engineered_features.append(f'{col}_log')\n",
    "        feature_descriptions[f'{col}_log'] = f\"Log-transformed {col} using np.log1p with negative value clipping\"\n",
    "    else:\n",
    "        print(f\"  ⚠️ {col} column not found - skipping log transformation\")\n",
    "\n",
    "print(\"\\n🔀 6. ONE-HOT ENCODING CATEGORICAL FEATURES\")\n",
    "# 6. One-hot encode categorical features\n",
    "categorical_features_to_encode = ['gender', 'smoking_status', 'exercise_level', 'family_history']\n",
    "\n",
    "# Add our newly created categorical features\n",
    "if 'bmi_group' in train_engineered.columns:\n",
    "    categorical_features_to_encode.append('bmi_group')\n",
    "if 'age_group' in train_engineered.columns:\n",
    "    categorical_features_to_encode.append('age_group')\n",
    "\n",
    "# Filter to only include columns that exist\n",
    "available_categorical_features = [col for col in categorical_features_to_encode \n",
    "                                 if col in train_engineered.columns]\n",
    "\n",
    "print(f\"  Available categorical features for encoding: {available_categorical_features}\")\n",
    "\n",
    "# Apply one-hot encoding\n",
    "for col in available_categorical_features:\n",
    "    # Get unique values from training data to ensure consistency\n",
    "    unique_values = sorted(train_engineered[col].unique())\n",
    "    \n",
    "    # Create one-hot encoded columns for training data\n",
    "    train_dummies = pd.get_dummies(train_engineered[col], prefix=col, prefix_sep='_')\n",
    "    test_dummies = pd.get_dummies(test_engineered[col], prefix=col, prefix_sep='_')\n",
    "    \n",
    "    # Ensure test data has same columns as training data\n",
    "    for dummy_col in train_dummies.columns:\n",
    "        if dummy_col not in test_dummies.columns:\n",
    "            test_dummies[dummy_col] = 0\n",
    "    \n",
    "    # Reorder test columns to match training columns\n",
    "    test_dummies = test_dummies[train_dummies.columns]\n",
    "    \n",
    "    # Add to dataframes\n",
    "    train_engineered = pd.concat([train_engineered, train_dummies], axis=1)\n",
    "    test_engineered = pd.concat([test_engineered, test_dummies], axis=1)\n",
    "    \n",
    "    # Track new features\n",
    "    new_cols = list(train_dummies.columns)\n",
    "    engineered_features.extend(new_cols)\n",
    "    feature_descriptions[f'{col}_onehot'] = f\"One-hot encoded {col}: {new_cols}\"\n",
    "    \n",
    "    print(f\"    {col}: Created {len(new_cols)} one-hot encoded features\")\n",
    "\n",
    "print(\"\\n🔄 7. CREATING INTERACTION FEATURES\")\n",
    "# 7. Create interaction features\n",
    "interaction_features = []\n",
    "\n",
    "# Age-BMI interaction\n",
    "if 'age' in train_engineered.columns and 'bmi' in train_engineered.columns:\n",
    "    train_engineered['age_bmi_interaction'] = train_engineered['age'] * train_engineered['bmi']\n",
    "    test_engineered['age_bmi_interaction'] = test_engineered['age'] * test_engineered['bmi']\n",
    "    \n",
    "    interaction_features.append('age_bmi_interaction')\n",
    "    feature_descriptions['age_bmi_interaction'] = \"Interaction feature: age * bmi\"\n",
    "    print(f\"  ✅ Created age_bmi_interaction\")\n",
    "else:\n",
    "    print(f\"  ⚠️ Age or BMI columns not found - skipping age-BMI interaction\")\n",
    "\n",
    "# Cholesterol-smoking interaction (using encoded smoking status)\n",
    "cholesterol_col = None\n",
    "for col in ['cholesterol', 'total_cholesterol', 'chol']:\n",
    "    if col in train_engineered.columns:\n",
    "        cholesterol_col = col\n",
    "        break\n",
    "\n",
    "smoking_encoded_col = None\n",
    "if 'smoking_status' in train_engineered.columns:\n",
    "    # Use the original encoded smoking status from earlier preprocessing\n",
    "    smoking_encoded_col = 'smoking_status'\n",
    "\n",
    "if cholesterol_col and smoking_encoded_col:\n",
    "    train_engineered['cholesterol_smoking_interaction'] = (train_engineered[cholesterol_col] * \n",
    "                                                          train_engineered[smoking_encoded_col])\n",
    "    test_engineered['cholesterol_smoking_interaction'] = (test_engineered[cholesterol_col] * \n",
    "                                                         test_engineered[smoking_encoded_col])\n",
    "    \n",
    "    interaction_features.append('cholesterol_smoking_interaction')\n",
    "    feature_descriptions['cholesterol_smoking_interaction'] = f\"Interaction feature: {cholesterol_col} * {smoking_encoded_col}\"\n",
    "    print(f\"  ✅ Created cholesterol_smoking_interaction using {cholesterol_col} and {smoking_encoded_col}\")\n",
    "else:\n",
    "    print(f\"  ⚠️ Cholesterol ({cholesterol_col}) or smoking ({smoking_encoded_col}) columns not found - skipping interaction\")\n",
    "\n",
    "engineered_features.extend(interaction_features)\n",
    "\n",
    "print(f\"\\n📊 FEATURE ENGINEERING SUMMARY:\")\n",
    "print(f\"  Total new features created: {len(engineered_features)}\")\n",
    "print(f\"  Original training shape: {train_processed.shape}\")\n",
    "print(f\"  Engineered training shape: {train_engineered.shape}\")\n",
    "print(f\"  Original test shape: {test_processed.shape}\")\n",
    "print(f\"  Engineered test shape: {test_engineered.shape}\")\n",
    "\n",
    "print(f\"\\n🔍 New Features Overview:\")\n",
    "sample_features = engineered_features[:10] if len(engineered_features) > 10 else engineered_features\n",
    "for feature in sample_features:\n",
    "    print(f\"  • {feature}\")\n",
    "if len(engineered_features) > 10:\n",
    "    print(f\"  ... and {len(engineered_features) - 10} more features\")\n",
    "\n",
    "# Store feature engineering information\n",
    "feature_engineering_info = {\n",
    "    'engineered_features': engineered_features,\n",
    "    'feature_descriptions': feature_descriptions,\n",
    "    'original_shape_train': train_processed.shape,\n",
    "    'engineered_shape_train': train_engineered.shape,\n",
    "    'original_shape_test': test_processed.shape,\n",
    "    'engineered_shape_test': test_engineered.shape,\n",
    "    'feature_engineering_steps': [\n",
    "        '1. BMI group categorization (medical standards)',\n",
    "        '2. Age group binning (life stages)',\n",
    "        '3. High blood pressure binary indicator',\n",
    "        '4. High medication count binary indicator',\n",
    "        '5. Log transformation of skewed features',\n",
    "        '6. One-hot encoding of categorical features',\n",
    "        '7. Interaction features (age*bmi, cholesterol*smoking)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Update the processed dataframes with engineered features\n",
    "train_processed = train_engineered.copy()\n",
    "test_processed = test_engineered.copy()\n",
    "\n",
    "print(\"\\n✅ Advanced feature engineering completed!\")\n",
    "print(\"📈 Enhanced features ready for model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf300cc5",
   "metadata": {},
   "source": [
    "### 3.5 Feature Engineering Verification\n",
    "For data integrity and quality assurance, we need to verify that feature engineering was applied consistently across datasets:\n",
    "\n",
    "- **Shape Consistency**: Compare dataset dimensions to ensure matching feature counts\n",
    "- **Feature Alignment**: Verify identical feature sets exist in both training and test data\n",
    "- **Engineering Validation**: Confirm all engineered features are present in both datasets\n",
    "- **Sample Verification**: Check actual feature values to ensure proper transformation\n",
    "- **Data Quality Check**: Detect any discrepancies that could cause model errors\n",
    "- This verification step prevents runtime errors during model training and ensures data consistency across the machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f546336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 VERIFICATION: FEATURE ENGINEERING APPLIED TO BOTH DATASETS\n",
    "print(\"=\" * 60)\n",
    "print(\"✅ 3.5 VERIFICATION: FEATURE ENGINEERING APPLIED TO BOTH DATASETS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"🔍 Verifying feature engineering consistency between train and test datasets...\")\n",
    "\n",
    "# Verify that both datasets have the same engineered features\n",
    "train_columns = set(train_engineered.columns)\n",
    "test_columns = set(test_engineered.columns)\n",
    "\n",
    "print(f\"\\n📊 Dataset Shape Comparison:\")\n",
    "print(f\"  Training dataset: {train_engineered.shape}\")\n",
    "print(f\"  Test dataset: {test_engineered.shape}\")\n",
    "\n",
    "print(f\"\\n🔧 Feature Consistency Check:\")\n",
    "if train_columns == test_columns:\n",
    "    print(f\"  ✅ Both datasets have identical feature sets ({len(train_columns)} features)\")\n",
    "else:\n",
    "    missing_in_test = train_columns - test_columns\n",
    "    missing_in_train = test_columns - train_columns\n",
    "    if missing_in_test:\n",
    "        print(f\"  ⚠️ Features missing in test dataset: {missing_in_test}\")\n",
    "    if missing_in_train:\n",
    "        print(f\"  ⚠️ Features missing in training dataset: {missing_in_train}\")\n",
    "\n",
    "# Verify specific engineered features exist in both datasets\n",
    "print(f\"\\n🔧 Engineered Features Verification:\")\n",
    "for feature in engineered_features[:10]:  # Check first 10 for brevity\n",
    "    in_train = feature in train_engineered.columns\n",
    "    in_test = feature in test_engineered.columns\n",
    "    status = \"✅\" if (in_train and in_test) else \"❌\"\n",
    "    print(f\"  {status} {feature}: Train={in_train}, Test={in_test}\")\n",
    "\n",
    "if len(engineered_features) > 10:\n",
    "    print(f\"  ... and {len(engineered_features) - 10} more features verified\")\n",
    "\n",
    "# Show sample of engineered features for both datasets\n",
    "print(f\"\\n📋 Sample Engineered Features Comparison:\")\n",
    "sample_engineered = [f for f in engineered_features[:5] if f in train_engineered.columns]\n",
    "if sample_engineered:\n",
    "    print(f\"  Sample features: {sample_engineered}\")\n",
    "    print(f\"  Training data sample:\")\n",
    "    print(f\"    {train_engineered[sample_engineered].head(2).to_dict('records')}\")\n",
    "    print(f\"  Test data sample:\")\n",
    "    print(f\"    {test_engineered[sample_engineered].head(2).to_dict('records')}\")\n",
    "\n",
    "print(f\"\\n✅ Feature engineering successfully applied to both train and test datasets!\")\n",
    "print(f\"🔄 Data consistency verified - ready for export!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46510a45",
   "metadata": {},
   "source": [
    "### 3.6 Data Export and Pipeline Component Preservation\n",
    "\n",
    "For reproducibility and production deployment, we need to save all preprocessing components:\n",
    "- **Processed Datasets**: Export clean training and test data for model training\n",
    "- **Pipeline Components**: Save all transformers (encoders, scalers, balancers) for future use\n",
    "- **Feature Engineering**: Save all feature engineering metadata and transformations\n",
    "- **Metadata Documentation**: Create comprehensive summaries of all preprocessing steps\n",
    "- **Reproducibility**: Enable exact replication of preprocessing on new data\n",
    "\n",
    "This ensures our preprocessing pipeline can be deployed in production and applied consistently to new incoming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11119d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 DATA EXPORT AND PIPELINE COMPONENT PRESERVATION\n",
    "print(\"=\"*60)\n",
    "print(\"💾 3.5 DATA EXPORT AND PIPELINE COMPONENT PRESERVATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"🔄 Exporting preprocessed datasets and metadata to '{output_dir}' folder...\")\n",
    "\n",
    "# Export preprocessed training data\n",
    "train_processed.to_csv(os.path.join(output_dir, 'train_processed.csv'), index=False)\n",
    "print(f\"  ✅ Exported {output_dir}/train_processed.csv: {train_processed.shape}\")\n",
    "\n",
    "# Export preprocessed test data\n",
    "test_processed.to_csv(os.path.join(output_dir, 'test_processed.csv'), index=False)\n",
    "print(f\"  ✅ Exported {output_dir}/test_processed.csv: {test_processed.shape}\")\n",
    "\n",
    "# Export all preprocessing components\n",
    "print(f\"\\n💾 Saving preprocessing components...\")\n",
    "\n",
    "# Label encoders\n",
    "with open(os.path.join(output_dir, 'label_encoders.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "print(f\"  ✅ Exported {output_dir}/label_encoders.pkl ({len(label_encoders)} encoders)\")\n",
    "\n",
    "# Scaler\n",
    "with open(os.path.join(output_dir, 'scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"  ✅ Exported {output_dir}/scaler.pkl\")\n",
    "\n",
    "# KNN Imputer\n",
    "with open(os.path.join(output_dir, 'knn_imputer.pkl'), 'wb') as f:\n",
    "    pickle.dump(imputation_model, f)\n",
    "print(f\"  ✅ Exported {output_dir}/knn_imputer.pkl\")\n",
    "\n",
    "# Class balancing information (create default if not exists)\n",
    "if 'balancing_info' not in globals():\n",
    "    balancing_info = {\n",
    "        'method': 'Not yet applied',\n",
    "        'original_distribution': {},\n",
    "        'balanced_distribution': {},\n",
    "        'original_samples': 0,\n",
    "        'balanced_samples': 0,\n",
    "        'imbalance_improvement': 'Will be determined after feature preparation',\n",
    "        'timestamp': pd.Timestamp.now()\n",
    "    }\n",
    "\n",
    "with open(os.path.join(output_dir, 'class_balancing_info.pkl'), 'wb') as f:\n",
    "    pickle.dump(balancing_info, f)\n",
    "print(f\"  ✅ Exported {output_dir}/class_balancing_info.pkl\")\n",
    "\n",
    "# Feature engineering information\n",
    "with open(os.path.join(output_dir, 'feature_engineering_info.pkl'), 'wb') as f:\n",
    "    pickle.dump(feature_engineering_info, f)\n",
    "print(f\"  ✅ Exported {output_dir}/feature_engineering_info.pkl\")\n",
    "\n",
    "# Create feature columns list for later use\n",
    "feature_columns = [col for col in train_processed.columns \n",
    "                  if col not in ['diagnosis', 'diagnosis_code']]\n",
    "\n",
    "# Create comprehensive preprocessing summary\n",
    "preprocessing_summary = {\n",
    "    'numerical_columns': numerical_cols,\n",
    "    'categorical_columns': categorical_columns,\n",
    "    'feature_columns': feature_columns,\n",
    "    'numerical_features_scaled': numerical_features_for_scaling,\n",
    "    'engineered_features': engineered_features,\n",
    "    'feature_descriptions': feature_descriptions,\n",
    "    'knn_imputer_params': {\n",
    "        'n_neighbors': imputation_model.n_neighbors,\n",
    "        'weights': imputation_model.weights,\n",
    "        'metric': imputation_model.metric\n",
    "    },\n",
    "    'label_encoders_info': {col: list(le.classes_) for col, le in label_encoders.items()},\n",
    "    'scaler_info': {\n",
    "        'feature_names': numerical_features_for_scaling,\n",
    "        'means': scaler.mean_.tolist(),\n",
    "        'scales': scaler.scale_.tolist()\n",
    "    },\n",
    "    'class_balancing_info': balancing_info,\n",
    "    'feature_engineering_info': feature_engineering_info,\n",
    "    'preprocessing_steps': [\n",
    "        '1. Missing value imputation (KNN-based approach)',\n",
    "        '2. Categorical encoding (LabelEncoder fit on training data)',\n",
    "        '3. Numerical feature scaling (StandardScaler fit on training data)',\n",
    "        '4. Class balancing (SMOTE if needed)',\n",
    "        '4.1. Advanced feature engineering (BMI groups, age groups, clinical indicators, interactions)',\n",
    "        '5. Strict train/test separation maintained'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, 'preprocessing_summary.pkl'), 'wb') as f:\n",
    "    pickle.dump(preprocessing_summary, f)\n",
    "print(f\"  ✅ Exported {output_dir}/preprocessing_summary.pkl\")\n",
    "\n",
    "print(f\"\\n📊 Final Preprocessing Summary:\")\n",
    "print(f\"• Training data: {train_processed.shape[0]} rows, {train_processed.shape[1]} columns\")\n",
    "print(f\"• Test data: {test_processed.shape[0]} rows, {test_processed.shape[1]} columns\")\n",
    "print(f\"• Numerical features: {len(numerical_cols)} (all scaled)\")\n",
    "print(f\"• Categorical features: {len(categorical_columns)} (all encoded)\")\n",
    "print(f\"• Engineered features: {len(engineered_features)} (clinical indicators, interactions, transformations)\")\n",
    "print(f\"• Total features for modeling: {len(feature_columns)}\")\n",
    "print(f\"• Class balancing: {balancing_info['method']}\")\n",
    "\n",
    "print(f\"\\n🔒 Data Integrity Verification:\")\n",
    "print(f\"• ✅ All transformers fit ONLY on training data\")\n",
    "print(f\"• ✅ Same transformations applied to both train and test\")\n",
    "print(f\"• ✅ No data leakage from test to train\")\n",
    "print(f\"• ✅ All preprocessing components exported for reproducibility\")\n",
    "print(f\"• ✅ Feature engineering applied consistently across datasets\")\n",
    "\n",
    "print(f\"\\n📁 Exported Files (in '{output_dir}' folder):\")\n",
    "print(f\"• {output_dir}/train_processed.csv & {output_dir}/test_processed.csv\")\n",
    "print(f\"• {output_dir}/label_encoders.pkl, {output_dir}/scaler.pkl, {output_dir}/knn_imputer.pkl\")\n",
    "print(f\"• {output_dir}/class_balancing_info.pkl, {output_dir}/feature_engineering_info.pkl\")\n",
    "print(f\"• {output_dir}/preprocessing_summary.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎉 COMPREHENSIVE PREPROCESSING WITH FEATURE ENGINEERING COMPLETED!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"📈 Enhanced features with domain knowledge ready for model training!\")\n",
    "print(\"🚀 Ready for advanced model training with hyperparameter tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1e401",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Features and Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare features (X) and target (y) for training\n",
    "# Create output directory if it doesn't exist for pipeline components\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# IMPORTANT: Filter feature columns and convert all to numerical\n",
    "# Handle both original numerical and one-hot encoded categorical features\n",
    "print(\"Preparing numerical features from processed data...\")\n",
    "\n",
    "# Get the feature columns (excluding target columns)\n",
    "feature_columns_clean = [col for col in train_processed.columns \n",
    "                        if col not in ['diagnosis', 'diagnosis_code']]\n",
    "\n",
    "# Prepare training features\n",
    "X_train = train_processed[feature_columns_clean].copy()\n",
    "\n",
    "# Convert boolean and categorical columns to numerical\n",
    "print(\"Converting all features to numerical format...\")\n",
    "for col in X_train.columns:\n",
    "    col_dtype = X_train[col].dtype\n",
    "    if col_dtype == 'object' or col_dtype == 'category':\n",
    "        # Handle string categorical columns\n",
    "        if X_train[col].dtype == 'object':\n",
    "            print(f\"  Converting object column {col} to numerical\")\n",
    "            # Try to convert to numerical, if not possible, use label encoding\n",
    "            try:\n",
    "                X_train[col] = pd.to_numeric(X_train[col], errors='raise')\n",
    "            except:\n",
    "                le_temp = LabelEncoder()\n",
    "                X_train[col] = le_temp.fit_transform(X_train[col].astype(str))\n",
    "    elif col_dtype == 'bool':\n",
    "        print(f\"  Converting boolean column {col} to int\")\n",
    "        X_train[col] = X_train[col].astype(int)\n",
    "\n",
    "# Apply same transformations to test data\n",
    "X_test = test_processed[feature_columns_clean].copy()\n",
    "for col in X_test.columns:\n",
    "    col_dtype = X_test[col].dtype\n",
    "    if col_dtype == 'object' or col_dtype == 'category':\n",
    "        if X_test[col].dtype == 'object':\n",
    "            try:\n",
    "                X_test[col] = pd.to_numeric(X_test[col], errors='raise')\n",
    "            except:\n",
    "                # Use same encoding as training data\n",
    "                if col in X_train.columns:\n",
    "                    unique_vals = X_train[col].unique()\n",
    "                    X_test[col] = X_test[col].map(dict(zip(\n",
    "                        train_processed[col].unique(), \n",
    "                        unique_vals\n",
    "                    ))).fillna(0).astype(int)\n",
    "    elif col_dtype == 'bool':\n",
    "        X_test[col] = X_test[col].astype(int)\n",
    "\n",
    "# IMPORTANT FIX: diagnosis_code was scaled during preprocessing, but we need discrete labels for classification\n",
    "y_train_scaled = train_processed['diagnosis_code']\n",
    "diagnosis_encoder = LabelEncoder()\n",
    "y_train = diagnosis_encoder.fit_transform(y_train_scaled)\n",
    "y_train = pd.Series(y_train, name='diagnosis_class')\n",
    "\n",
    "print(f\"\\nTraining features shape: {X_train.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "\n",
    "# Verify all features are numerical\n",
    "print(f\"\\nFeature data types verification:\")\n",
    "non_numerical = X_train.select_dtypes(exclude=['number']).columns.tolist()\n",
    "if non_numerical:\n",
    "    print(f\"  ⚠️ Non-numerical columns still found: {non_numerical}\")\n",
    "    # Force convert remaining non-numerical columns\n",
    "    for col in non_numerical:\n",
    "        print(f\"    Force converting {col}...\")\n",
    "        X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0)\n",
    "        X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0)\n",
    "else:\n",
    "    print(f\"  ✅ All {X_train.shape[1]} features are numerical\")\n",
    "\n",
    "print(f\"\\nTarget classes in training data (discrete labels):\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "\n",
    "# Save the diagnosis encoder for later use\n",
    "with open(os.path.join(output_dir, 'diagnosis_encoder.pkl'), 'wb') as f:\n",
    "    pickle.dump(diagnosis_encoder, f)\n",
    "print(f\"\\n✅ Saved diagnosis encoder to {output_dir}/diagnosis_encoder.pkl\")\n",
    "\n",
    "# Update feature_columns for consistency\n",
    "feature_columns = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac262a",
   "metadata": {},
   "source": [
    "### 4.1 Class Balancing and Data Sampling\n",
    "\n",
    "**Purpose**: Address class imbalance to improve model performance and reduce bias toward majority classes.\n",
    "\n",
    "**Why This Matters**:\n",
    "- Class imbalance can lead to poor performance on minority classes\n",
    "- Models may become biased toward predicting majority classes\n",
    "- Advanced sampling techniques like SMOTE create synthetic samples rather than just duplicating existing ones\n",
    "- SMOTE+Tomek combines oversampling with cleaning to reduce overfitting risk\n",
    "\n",
    "**Approach**:\n",
    "1. **SMOTE+Tomek**: Preferred method - combines SMOTE oversampling with Tomek link cleaning\n",
    "   - SMOTE creates synthetic minority samples using nearest neighbors\n",
    "   - Tomek links remove borderline samples that may cause overfitting\n",
    "   - Better generalization than simple oversampling\n",
    "2. **SMOTE**: Fallback if Tomek cleaning fails\n",
    "3. **Random Oversampling**: Last resort for compatibility\n",
    "\n",
    "**Overfitting Prevention**:\n",
    "- Synthetic sample generation preserves feature space characteristics\n",
    "- Tomek link cleaning removes ambiguous borderline samples\n",
    "- Conservative approach: only balance to reasonable ratios, not perfect balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e46a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 CLASS BALANCING AND DATA SAMPLING\n",
    "print(\"=\" * 60)\n",
    "print(\"⚖️ 4.1 CLASS BALANCING AND DATA SAMPLING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"🔄 Starting class balance analysis...\")\n",
    "\n",
    "# Analyze current class distribution\n",
    "class_counts = Counter(y_train)\n",
    "total_samples = len(y_train)\n",
    "print(f\"\\n📊 Current Class Distribution:\")\n",
    "for class_label in sorted(class_counts.keys()):\n",
    "    count = class_counts[class_label]\n",
    "    percentage = (count / total_samples) * 100\n",
    "    print(f\"  Class {class_label}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# Calculate imbalance metrics\n",
    "max_count = max(class_counts.values())\n",
    "min_count = min(class_counts.values())\n",
    "imbalance_ratio = max_count / min_count\n",
    "IMBALANCE_THRESHOLD = 2.0\n",
    "\n",
    "print(f\"\\n📈 Imbalance Analysis:\")\n",
    "print(f\"  Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "print(f\"  Most common class: {max_count} samples\")\n",
    "print(f\"  Least common class: {min_count} samples\")\n",
    "\n",
    "# Apply balancing if needed\n",
    "if imbalance_ratio > IMBALANCE_THRESHOLD:\n",
    "    print(f\"  ⚠️ Significant class imbalance detected (ratio > {IMBALANCE_THRESHOLD})\")\n",
    "    \n",
    "    # Try SMOTE+Tomek first (best for avoiding overfitting)\n",
    "    try:\n",
    "        print(\"  🔄 Applying SMOTE+Tomek balancing...\")\n",
    "        print(\"    📊 SMOTE: Creating synthetic minority samples\")\n",
    "        print(\"    🧹 Tomek: Cleaning borderline samples to reduce overfitting\")\n",
    "        \n",
    "        # Use conservative sampling strategy - don't aim for perfect balance\n",
    "        # This helps prevent overfitting by not over-representing minority classes\n",
    "        target_ratio = min(0.8, max_count / min_count * 0.6)  # Conservative ratio\n",
    "        sampling_strategy = {\n",
    "            cls: max(count, int(max_count * 0.6)) \n",
    "            for cls, count in class_counts.items() \n",
    "            if count < max_count * 0.8\n",
    "        }\n",
    "        \n",
    "        # SMOTE+Tomek combines oversampling with cleaning\n",
    "        smote_tomek = SMOTETomek(\n",
    "            smote=SMOTE(random_state=42, k_neighbors=3),\n",
    "            tomek=TomekLinks(),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        X_balanced, y_balanced = smote_tomek.fit_resample(X_train, y_train)\n",
    "        balancing_method = \"SMOTE+Tomek\"\n",
    "        \n",
    "        print(\"  ✅ SMOTE+Tomek successful!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ SMOTE+Tomek failed: {str(e)}\")\n",
    "        \n",
    "        # Fallback to SMOTE only\n",
    "        try:\n",
    "            print(\"  🔄 Applying SMOTE balancing...\")\n",
    "            print(\"    📊 Creating synthetic minority samples using SMOTE\")\n",
    "            \n",
    "            smote = SMOTE(random_state=42, k_neighbors=min(3, min_count-1))\n",
    "            X_balanced, y_balanced = smote.fit_resample(X_train, y_train)\n",
    "            balancing_method = \"SMOTE\"\n",
    "            \n",
    "            print(\"  ✅ SMOTE successful!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️ SMOTE failed: {str(e)}\")\n",
    "            \n",
    "            # Final fallback to random oversampling\n",
    "            print(\"  🔄 Applying Random Oversampling balancing...\")\n",
    "            print(\"    ⚠️ Using basic oversampling (higher overfitting risk)\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b1294",
   "metadata": {},
   "source": [
    "## Step 5: Model Training with Parameter Tuning\n",
    "\n",
    "Now that we have successfully preprocessed our data and achieved balanced classes, we will train three different machine learning models with hyperparameter tuning to find the optimal configuration for each:\n",
    "\n",
    "1. **Logistic Regression with Parameter Tuning**\n",
    "2. **XGBoost with Parameter Tuning** \n",
    "3. **Random Forest with Parameter Tuning**\n",
    "\n",
    "Each model will be optimized using GridSearchCV with cross-validation to ensure robust performance and prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa83b65",
   "metadata": {},
   "source": [
    "### 5.1 Parameter Tuning and Training - Logistic Regression\n",
    "\n",
    "Logistic Regression is a linear classifier that works well for binary classification problems. We'll tune the following hyperparameters:\n",
    "\n",
    "- **C (Regularization strength)**: Controls the strength of regularization (inverse of lambda)\n",
    "- **penalty**: Type of regularization (L1, L2, or ElasticNet)\n",
    "- **solver**: Algorithm for optimization\n",
    "- **max_iter**: Maximum iterations for convergence\n",
    "\n",
    "**Advantages of Logistic Regression:**\n",
    "- Fast training and prediction\n",
    "- Provides probability estimates\n",
    "- Less prone to overfitting with regularization\n",
    "- Interpretable coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4965760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GLOBAL WARNING SUPPRESSION ==========\n",
    "print(\"🔧 CONFIGURING ENVIRONMENT FOR CLEAN MODEL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Suppress all sklearn and numpy warnings for cleaner output\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Suppress specific warning categories\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning) \n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Specific sklearn warnings\n",
    "warnings.filterwarnings('ignore', message='.*sklearn.utils.parallel.*')\n",
    "warnings.filterwarnings('ignore', message='.*divide by zero encountered.*')\n",
    "warnings.filterwarnings('ignore', message='.*overflow encountered.*')\n",
    "warnings.filterwarnings('ignore', message='.*invalid value encountered.*')\n",
    "warnings.filterwarnings('ignore', message='.*max_iter was reached.*')\n",
    "warnings.filterwarnings('ignore', message='.*One or more of the test scores are non-finite.*')\n",
    "\n",
    "# Set environment variables to optimize parallel processing\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "os.environ['SKLEARN_PARALLEL_BACKEND'] = 'threading'\n",
    "os.environ['JOBLIB_MULTIPROCESSING'] = '0'  # Use threading instead of multiprocessing\n",
    "\n",
    "# Configure numpy error handling\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore', over='ignore')\n",
    "\n",
    "print(\"✅ Environment configured for clean parallel processing\")\n",
    "print(\"✅ All warnings suppressed for better readability\") \n",
    "print(\"✅ Parallel backend optimized for stability\")\n",
    "print(\"🚀 Ready for model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 STEP 5.1: LOGISTIC REGRESSION PARAMETER TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Set environment variables to reduce sklearn parallel warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "os.environ['SKLEARN_PARALLEL_BACKEND'] = 'threading'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "# Note: Different solvers support different penalties, so we'll create compatible combinations\n",
    "lr_param_grid = [\n",
    "    # L1 penalty with liblinear solver (good for feature selection)\n",
    "    {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'penalty': ['l1'],\n",
    "        'solver': ['liblinear'],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    },\n",
    "    # L2 penalty with liblinear solver (default combination)\n",
    "    {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['liblinear'],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    },\n",
    "    # L1 and L2 penalties with saga solver (supports all penalties)\n",
    "    {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['saga'],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    },\n",
    "    # ElasticNet penalty with saga solver and l1_ratio\n",
    "    {\n",
    "        'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'penalty': ['elasticnet'],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [0.1, 0.5, 0.7, 0.9],  # Required for elasticnet\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"📊 Parameter grid for Logistic Regression:\")\n",
    "print(f\"  Grid 1 - L1 penalty with liblinear solver:\")\n",
    "print(f\"    • C: {lr_param_grid[0]['C']}\")\n",
    "print(f\"    • penalty: {lr_param_grid[0]['penalty']}\")\n",
    "print(f\"    • solver: {lr_param_grid[0]['solver']}\")\n",
    "print(f\"  Grid 2 - L2 penalty with liblinear solver:\")\n",
    "print(f\"    • C: {lr_param_grid[1]['C']}\")\n",
    "print(f\"    • penalty: {lr_param_grid[1]['penalty']}\")\n",
    "print(f\"    • solver: {lr_param_grid[1]['solver']}\")\n",
    "print(f\"  Grid 3 - L1/L2 penalties with saga solver:\")\n",
    "print(f\"    • C: {lr_param_grid[2]['C']}\")\n",
    "print(f\"    • penalty: {lr_param_grid[2]['penalty']}\")\n",
    "print(f\"    • solver: {lr_param_grid[2]['solver']}\")\n",
    "print(f\"  Grid 4 - ElasticNet penalty with saga solver:\")\n",
    "print(f\"    • C: {lr_param_grid[3]['C']}\")\n",
    "print(f\"    • penalty: {lr_param_grid[3]['penalty']}\")\n",
    "print(f\"    • solver: {lr_param_grid[3]['solver']}\")\n",
    "print(f\"    • l1_ratio: {lr_param_grid[3]['l1_ratio']}\")\n",
    "\n",
    "print(f\"\\n💡 Using compatible parameter combinations to avoid solver-penalty conflicts\")\n",
    "\n",
    "# Create cross-validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "print(f\"\\n🔄 Starting GridSearchCV with {cv_strategy.n_splits}-fold cross-validation...\")\n",
    "print(f\"⏱️ This may take a few minutes...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform grid search\n",
    "lr_grid_search = GridSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_grid=lr_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Parallel execution for faster training\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "lr_grid_search.fit(X_balanced, y_balanced)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✅ GridSearchCV completed in {training_time:.2f} seconds\")\n",
    "print(f\"🎯 Best cross-validation score: {lr_grid_search.best_score_:.4f}\")\n",
    "print(f\"📋 Best parameters:\")\n",
    "for param, value in lr_grid_search.best_params_.items():\n",
    "    print(f\"  • {param}: {value}\")\n",
    "\n",
    "# Get the best model\n",
    "best_lr_model = lr_grid_search.best_estimator_\n",
    "\n",
    "# Train accuracy\n",
    "y_train_pred_lr = best_lr_model.predict(X_balanced)\n",
    "train_accuracy_lr = accuracy_score(y_balanced, y_train_pred_lr)\n",
    "\n",
    "print(f\"\\n📈 Training Results:\")\n",
    "print(f\"  • Best CV Score: {lr_grid_search.best_score_:.4f}\")\n",
    "print(f\"  • Training Accuracy: {train_accuracy_lr:.4f}\")\n",
    "print(f\"  • Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Store results\n",
    "lr_results = {\n",
    "    'model': best_lr_model,\n",
    "    'best_params': lr_grid_search.best_params_,\n",
    "    'best_score': lr_grid_search.best_score_,\n",
    "    'train_accuracy': train_accuracy_lr,\n",
    "    'training_time': training_time,\n",
    "    'grid_search': lr_grid_search\n",
    "}\n",
    "\n",
    "print(\"✅ Logistic Regression parameter tuning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae717aa",
   "metadata": {},
   "source": [
    "### 5.2 Parameter Tuning and Training - XGBoost\n",
    "\n",
    "XGBoost is a powerful gradient boosting algorithm known for its performance in structured data problems. We'll tune the following key hyperparameters:\n",
    "\n",
    "- **n_estimators**: Number of boosting rounds\n",
    "- **max_depth**: Maximum depth of trees\n",
    "- **learning_rate**: Step size shrinkage to prevent overfitting\n",
    "- **subsample**: Fraction of samples for each tree\n",
    "- **colsample_bytree**: Fraction of features for each tree\n",
    "\n",
    "**Advantages of XGBoost:**\n",
    "- Excellent performance on structured data\n",
    "- Built-in regularization\n",
    "- Handles missing values automatically\n",
    "- Feature importance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 STEP 5.2: XGBOOST PARAMETER TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Set environment variables to reduce sklearn parallel warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "os.environ['SKLEARN_PARALLEL_BACKEND'] = 'threading'\n",
    "\n",
    "# Check if XGBoost is available\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_available = True\n",
    "    print(\"✅ XGBoost is available\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ XGBoost not installed. Installing...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
    "    import xgboost as xgb\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_available = True\n",
    "\n",
    "# Define parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "print(f\"📊 Parameter grid for XGBoost:\")\n",
    "for param, values in xgb_param_grid.items():\n",
    "    print(f\"  • {param}: {values}\")\n",
    "\n",
    "# For computational efficiency, we'll use a reduced grid first\n",
    "xgb_reduced_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "print(f\"\\n🚀 Using reduced parameter grid for efficiency:\")\n",
    "for param, values in xgb_reduced_grid.items():\n",
    "    print(f\"  • {param}: {values}\")\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "print(f\"\\n🔄 Starting GridSearchCV with {cv_strategy.n_splits}-fold cross-validation...\")\n",
    "print(f\"⏱️ This may take several minutes...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform grid search\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=xgb_reduced_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Parallel execution for faster training\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "xgb_grid_search.fit(X_balanced, y_balanced)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✅ GridSearchCV completed in {training_time:.2f} seconds\")\n",
    "print(f\"🎯 Best cross-validation score: {xgb_grid_search.best_score_:.4f}\")\n",
    "print(f\"📋 Best parameters:\")\n",
    "for param, value in xgb_grid_search.best_params_.items():\n",
    "    print(f\"  • {param}: {value}\")\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "# Train accuracy\n",
    "y_train_pred_xgb = best_xgb_model.predict(X_balanced)\n",
    "train_accuracy_xgb = accuracy_score(y_balanced, y_train_pred_xgb)\n",
    "\n",
    "print(f\"\\n📈 Training Results:\")\n",
    "print(f\"  • Best CV Score: {xgb_grid_search.best_score_:.4f}\")\n",
    "print(f\"  • Training Accuracy: {train_accuracy_xgb:.4f}\")\n",
    "print(f\"  • Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Store results\n",
    "xgb_results = {\n",
    "    'model': best_xgb_model,\n",
    "    'best_params': xgb_grid_search.best_params_,\n",
    "    'best_score': xgb_grid_search.best_score_,\n",
    "    'train_accuracy': train_accuracy_xgb,\n",
    "    'training_time': training_time,\n",
    "    'grid_search': xgb_grid_search\n",
    "}\n",
    "\n",
    "print(\"✅ XGBoost parameter tuning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff53c7f",
   "metadata": {},
   "source": [
    "### 5.3 Parameter Tuning and Training - Random Forest\n",
    "\n",
    "Random Forest is an ensemble method that combines multiple decision trees to create a robust classifier. We'll tune the following hyperparameters:\n",
    "\n",
    "- **n_estimators**: Number of trees in the forest\n",
    "- **max_depth**: Maximum depth of each tree\n",
    "- **min_samples_split**: Minimum samples required to split a node\n",
    "- **min_samples_leaf**: Minimum samples required at a leaf node\n",
    "- **max_features**: Number of features to consider for best split\n",
    "\n",
    "**Advantages of Random Forest:**\n",
    "- Reduces overfitting compared to single decision trees\n",
    "- Provides feature importance rankings\n",
    "- Handles missing values and outliers well\n",
    "- Works well with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bdfb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 STEP 5.3: RANDOM FOREST PARAMETER TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Set environment variables to reduce sklearn parallel warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "os.environ['SKLEARN_PARALLEL_BACKEND'] = 'threading'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "print(f\"📊 Parameter grid for Random Forest:\")\n",
    "for param, values in rf_param_grid.items():\n",
    "    print(f\"  • {param}: {values}\")\n",
    "\n",
    "# For computational efficiency, we'll use a reduced grid\n",
    "rf_reduced_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "print(f\"\\n🚀 Using reduced parameter grid for efficiency:\")\n",
    "for param, values in rf_reduced_grid.items():\n",
    "    print(f\"  • {param}: {values}\")\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "print(f\"\\n🔄 Starting GridSearchCV with {cv_strategy.n_splits}-fold cross-validation...\")\n",
    "print(f\"⏱️ This may take several minutes...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform grid search\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_reduced_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Parallel execution for faster training\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "rf_grid_search.fit(X_balanced, y_balanced)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✅ GridSearchCV completed in {training_time:.2f} seconds\")\n",
    "print(f\"🎯 Best cross-validation score: {rf_grid_search.best_score_:.4f}\")\n",
    "print(f\"📋 Best parameters:\")\n",
    "for param, value in rf_grid_search.best_params_.items():\n",
    "    print(f\"  • {param}: {value}\")\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Train accuracy\n",
    "y_train_pred_rf = best_rf_model.predict(X_balanced)\n",
    "train_accuracy_rf = accuracy_score(y_balanced, y_train_pred_rf)\n",
    "\n",
    "print(f\"\\n📈 Training Results:\")\n",
    "print(f\"  • Best CV Score: {rf_grid_search.best_score_:.4f}\")\n",
    "print(f\"  • Training Accuracy: {train_accuracy_rf:.4f}\")\n",
    "print(f\"  • Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Store results\n",
    "rf_results = {\n",
    "    'model': best_rf_model,\n",
    "    'best_params': rf_grid_search.best_params_,\n",
    "    'best_score': rf_grid_search.best_score_,\n",
    "    'train_accuracy': train_accuracy_rf,\n",
    "    'training_time': training_time,\n",
    "    'grid_search': rf_grid_search\n",
    "}\n",
    "\n",
    "print(\"✅ Random Forest parameter tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 STEP 5 SUMMARY: MODEL TRAINING RESULTS COMPARISON\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Compile all training results\n",
    "all_models = {\n",
    "    'Logistic Regression': lr_results,\n",
    "    'XGBoost': xgb_results,\n",
    "    'Random Forest': rf_results\n",
    "}\n",
    "\n",
    "print(\"🏆 Model Performance Comparison:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model':<20} {'CV Score':<12} {'Train Acc':<12} {'Time (s)':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_cv_score = 0\n",
    "\n",
    "for model_name, results in all_models.items():\n",
    "    cv_score = results['best_score']\n",
    "    train_acc = results['train_accuracy']\n",
    "    time_taken = results['training_time']\n",
    "    \n",
    "    print(f\"{model_name:<20} {cv_score:<12.4f} {train_acc:<12.4f} {time_taken:<10.2f}\")\n",
    "    \n",
    "    if cv_score > best_cv_score:\n",
    "        best_cv_score = cv_score\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"🥇 Best performing model: {best_model_name} (CV Score: {best_cv_score:.4f})\")\n",
    "\n",
    "# Store the best overall model\n",
    "best_overall_model = all_models[best_model_name]['model']\n",
    "\n",
    "print(f\"\\n🎯 Training Phase Summary:\")\n",
    "print(f\"  ✅ All three models trained successfully\")\n",
    "print(f\"  ✅ Hyperparameter tuning completed for all models\")\n",
    "print(f\"  ✅ Cross-validation performed to ensure robust evaluation\")\n",
    "print(f\"  ✅ Best model identified: {best_model_name}\")\n",
    "\n",
    "# Save models for testing phase\n",
    "trained_models = {\n",
    "    'logistic_regression': lr_results,\n",
    "    'xgboost': xgb_results,\n",
    "    'random_forest': rf_results,\n",
    "    'best_model': best_overall_model,\n",
    "    'best_model_name': best_model_name\n",
    "}\n",
    "\n",
    "print(f\"🚀 Ready for Step 6: Model Testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2be97",
   "metadata": {},
   "source": [
    "### 5.4 Sequential Model Training (Alternative Approach)\n",
    "\n",
    "If you prefer to run all models sequentially in a single controlled execution, use the cell below instead of running individual model training cells. This approach ensures:\n",
    "\n",
    "- **Sequential Execution**: Models train one after another\n",
    "- **Resource Management**: No parallel processing conflicts  \n",
    "- **Progress Tracking**: Clear indication of which model is currently training\n",
    "- **Error Isolation**: If one model fails, others can still complete\n",
    "- **Comprehensive Results**: All models trained with identical settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42791536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 COMPREHENSIVE SEQUENTIAL MODEL TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(\"Training all three models sequentially to avoid resource conflicts...\")\n",
    "print(\"This may take several minutes - please be patient!\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Set environment variables to reduce sklearn parallel warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "os.environ['SKLEARN_PARALLEL_BACKEND'] = 'threading'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Create cross-validation strategy (reuse for all models)\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize results dictionary\n",
    "sequential_results = {}\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"🔍 MODEL 1/3: LOGISTIC REGRESSION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# ========== LOGISTIC REGRESSION ==========\n",
    "print(\"📊 Setting up Logistic Regression parameter grid...\")\n",
    "\n",
    "# Compatible parameter combinations for Logistic Regression\n",
    "lr_param_grid = [\n",
    "    # L1 penalty with liblinear solver\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'penalty': ['l1'],\n",
    "        'solver': ['liblinear'],\n",
    "        'max_iter': [1000, 2000]\n",
    "    },\n",
    "    # L2 penalty with liblinear solver\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['liblinear'],\n",
    "        'max_iter': [1000, 2000]\n",
    "    },\n",
    "    # L1/L2 penalties with saga solver\n",
    "    {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['saga'],\n",
    "        'max_iter': [1000, 2000]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"⏱️ Starting Logistic Regression training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_grid_search = GridSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_grid=lr_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Parallel execution for faster training\n",
    "    verbose=0  # Reduce output clutter\n",
    ")\n",
    "\n",
    "lr_grid_search.fit(X_balanced, y_balanced)\n",
    "lr_training_time = time.time() - start_time\n",
    "\n",
    "best_lr_model = lr_grid_search.best_estimator_\n",
    "y_train_pred_lr = best_lr_model.predict(X_balanced)\n",
    "lr_train_accuracy = accuracy_score(y_balanced, y_train_pred_lr)\n",
    "\n",
    "sequential_results['Logistic Regression'] = {\n",
    "    'model': best_lr_model,\n",
    "    'best_params': lr_grid_search.best_params_,\n",
    "    'best_score': lr_grid_search.best_score_,\n",
    "    'train_accuracy': lr_train_accuracy,\n",
    "    'training_time': lr_training_time,\n",
    "    'grid_search': lr_grid_search\n",
    "}\n",
    "\n",
    "print(f\"✅ Logistic Regression completed in {lr_training_time:.2f} seconds\")\n",
    "print(f\"   Best CV Score: {lr_grid_search.best_score_:.4f}\")\n",
    "print(f\"   Train Accuracy: {lr_train_accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"🔍 MODEL 2/3: XGBOOST\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# ========== XGBOOST ==========\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"📊 Setting up XGBoost parameter grid...\")\n",
    "    \n",
    "    # Reduced parameter grid for efficiency\n",
    "    xgb_param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    print(\"⏱️ Starting XGBoost training...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    xgb_model = XGBClassifier(\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    xgb_grid_search = GridSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_grid=xgb_param_grid,\n",
    "        cv=cv_strategy,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # Parallel execution for faster training\n",
    "        verbose=0  # Reduce output clutter\n",
    "    )\n",
    "    \n",
    "    xgb_grid_search.fit(X_balanced, y_balanced)\n",
    "    xgb_training_time = time.time() - start_time\n",
    "    \n",
    "    best_xgb_model = xgb_grid_search.best_estimator_\n",
    "    y_train_pred_xgb = best_xgb_model.predict(X_balanced)\n",
    "    xgb_train_accuracy = accuracy_score(y_balanced, y_train_pred_xgb)\n",
    "    \n",
    "    sequential_results['XGBoost'] = {\n",
    "        'model': best_xgb_model,\n",
    "        'best_params': xgb_grid_search.best_params_,\n",
    "        'best_score': xgb_grid_search.best_score_,\n",
    "        'train_accuracy': xgb_train_accuracy,\n",
    "        'training_time': xgb_training_time,\n",
    "        'grid_search': xgb_grid_search\n",
    "    }\n",
    "    \n",
    "    print(f\"✅ XGBoost completed in {xgb_training_time:.2f} seconds\")\n",
    "    print(f\"   Best CV Score: {xgb_grid_search.best_score_:.4f}\")\n",
    "    print(f\"   Train Accuracy: {xgb_train_accuracy:.4f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠️ XGBoost not available. Skipping XGBoost training.\")\n",
    "    sequential_results['XGBoost'] = None\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"🔍 MODEL 3/3: RANDOM FOREST\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# ========== RANDOM FOREST ==========\n",
    "print(\"📊 Setting up Random Forest parameter grid...\")\n",
    "\n",
    "# Reduced parameter grid for efficiency\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "print(\"⏱️ Starting Random Forest training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Parallel execution for faster training\n",
    "    verbose=0  # Reduce output clutter\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_balanced, y_balanced)\n",
    "rf_training_time = time.time() - start_time\n",
    "\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "y_train_pred_rf = best_rf_model.predict(X_balanced)\n",
    "rf_train_accuracy = accuracy_score(y_balanced, y_train_pred_rf)\n",
    "\n",
    "sequential_results['Random Forest'] = {\n",
    "    'model': best_rf_model,\n",
    "    'best_params': rf_grid_search.best_params_,\n",
    "    'best_score': rf_grid_search.best_score_,\n",
    "    'train_accuracy': rf_train_accuracy,\n",
    "    'training_time': rf_training_time,\n",
    "    'grid_search': rf_grid_search\n",
    "}\n",
    "\n",
    "print(f\"✅ Random Forest completed in {rf_training_time:.2f} seconds\")\n",
    "print(f\"   Best CV Score: {rf_grid_search.best_score_:.4f}\")\n",
    "print(f\"   Train Accuracy: {rf_train_accuracy:.4f}\")\n",
    "\n",
    "# ========== FINAL SUMMARY ==========\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"📊 SEQUENTIAL TRAINING COMPLETE - PERFORMANCE SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "total_time = sum([r['training_time'] for r in sequential_results.values() if r is not None])\n",
    "\n",
    "print(\"🏆 Model Performance Comparison:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model':<20} {'CV Score':<12} {'Train Acc':<12} {'Time (s)':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_cv_score = 0\n",
    "\n",
    "for model_name, results in sequential_results.items():\n",
    "    if results is not None:\n",
    "        cv_score = results['best_score']\n",
    "        train_acc = results['train_accuracy']\n",
    "        time_taken = results['training_time']\n",
    "        \n",
    "        print(f\"{model_name:<20} {cv_score:<12.4f} {train_acc:<12.4f} {time_taken:<10.2f}\")\n",
    "        \n",
    "        if cv_score > best_cv_score:\n",
    "            best_cv_score = cv_score\n",
    "            best_model_name = model_name\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"🥇 Best performing model: {best_model_name} (CV Score: {best_cv_score:.4f})\")\n",
    "print(f\"⏱️ Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Store results for use in subsequent steps\n",
    "trained_models = sequential_results\n",
    "best_overall_model = sequential_results[best_model_name]['model'] if best_model_name else None\n",
    "\n",
    "print(f\"\\n🎉 All models trained successfully in sequence!\")\n",
    "print(f\"📁 Results stored in 'trained_models' and 'sequential_results' variables\")\n",
    "print(f\"🚀 Ready for Step 6: Model Testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00dff7",
   "metadata": {},
   "source": [
    "## Step 6: Model Testing on Unseen Data\n",
    "\n",
    "Now that we have trained and optimized our three models, we will test their performance on the unseen test dataset. This step is crucial for evaluating how well our models generalize to new, previously unseen data.\n",
    "\n",
    "We will test each model separately and compare their performance:\n",
    "\n",
    "1. **Test Logistic Regression Model**\n",
    "2. **Test XGBoost Model**\n",
    "3. **Test Random Forest Model**\n",
    "\n",
    "For each model, we will evaluate:\n",
    "- **Accuracy**: Overall classification performance\n",
    "- **Precision, Recall, F1-Score**: Per-class performance metrics\n",
    "- **Confusion Matrix**: Detailed prediction breakdown\n",
    "- **Prediction Probabilities**: Confidence in predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757c8f4",
   "metadata": {},
   "source": [
    "### 6.1 Test Logistic Regression Model\n",
    "\n",
    "We'll test our optimized Logistic Regression model on the test dataset and analyze its performance across all evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧪 STEP 6.1: TESTING LOGISTIC REGRESSION MODEL\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Test Logistic Regression model\n",
    "lr_model = trained_models['logistic_regression']['model']\n",
    "\n",
    "print(f\"📋 Best Logistic Regression Parameters:\")\n",
    "for param, value in trained_models['logistic_regression']['best_params'].items():\n",
    "    print(f\"  • {param}: {value}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "print(f\"\\n🔮 Making predictions on test set...\")\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "y_test_proba_lr = lr_model.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy_lr = accuracy_score(y_test, y_test_pred_lr)\n",
    "test_report_lr = classification_report(y_test, y_test_pred_lr, output_dict=True)\n",
    "\n",
    "print(f\"\\n📊 Logistic Regression Test Results:\")\n",
    "print(f\"  • Test Accuracy: {test_accuracy_lr:.4f}\")\n",
    "print(f\"  • Training Accuracy: {trained_models['logistic_regression']['train_accuracy']:.4f}\")\n",
    "print(f\"  • CV Score: {trained_models['logistic_regression']['best_score']:.4f}\")\n",
    "\n",
    "# Calculate AUC-ROC if binary classification\n",
    "try:\n",
    "    auc_score_lr = roc_auc_score(y_test, y_test_proba_lr)\n",
    "    print(f\"  • AUC-ROC Score: {auc_score_lr:.4f}\")\n",
    "except:\n",
    "    print(f\"  • AUC-ROC: Not applicable for multiclass\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(f\"\\n📈 Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_lr))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_test_pred_lr)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.title('Logistic Regression - Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Store test results\n",
    "lr_test_results = {\n",
    "    'model_name': 'Logistic Regression',\n",
    "    'test_accuracy': test_accuracy_lr,\n",
    "    'train_accuracy': trained_models['logistic_regression']['train_accuracy'],\n",
    "    'cv_score': trained_models['logistic_regression']['best_score'],\n",
    "    'classification_report': test_report_lr,\n",
    "    'confusion_matrix': cm_lr,\n",
    "    'predictions': y_test_pred_lr,\n",
    "    'probabilities': y_test_proba_lr\n",
    "}\n",
    "\n",
    "# Calculate overfitting indicator\n",
    "overfitting_lr = trained_models['logistic_regression']['train_accuracy'] - test_accuracy_lr\n",
    "print(f\"\\n🎯 Model Performance Analysis:\")\n",
    "print(f\"  • Overfitting Indicator: {overfitting_lr:.4f}\")\n",
    "if overfitting_lr > 0.05:\n",
    "    print(f\"  ⚠️ Potential overfitting detected (train - test > 0.05)\")\n",
    "else:\n",
    "    print(f\"  ✅ Good generalization (minimal overfitting)\")\n",
    "\n",
    "print(\"✅ Logistic Regression testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60366b9a",
   "metadata": {},
   "source": [
    "### 6.2 Test XGBoost Model\n",
    "\n",
    "Now we'll test our optimized XGBoost model and compare its performance with the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧪 STEP 6.2: TESTING XGBOOST MODEL\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Test XGBoost model\n",
    "xgb_model = trained_models['xgboost']['model']\n",
    "\n",
    "print(f\"📋 Best XGBoost Parameters:\")\n",
    "for param, value in trained_models['xgboost']['best_params'].items():\n",
    "    print(f\"  • {param}: {value}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "print(f\"\\n🔮 Making predictions on test set...\")\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "y_test_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy_xgb = accuracy_score(y_test, y_test_pred_xgb)\n",
    "test_report_xgb = classification_report(y_test, y_test_pred_xgb, output_dict=True)\n",
    "\n",
    "print(f\"\\n📊 XGBoost Test Results:\")\n",
    "print(f\"  • Test Accuracy: {test_accuracy_xgb:.4f}\")\n",
    "print(f\"  • Training Accuracy: {trained_models['xgboost']['train_accuracy']:.4f}\")\n",
    "print(f\"  • CV Score: {trained_models['xgboost']['best_score']:.4f}\")\n",
    "\n",
    "# Calculate AUC-ROC if binary classification\n",
    "try:\n",
    "    auc_score_xgb = roc_auc_score(y_test, y_test_proba_xgb)\n",
    "    print(f\"  • AUC-ROC Score: {auc_score_xgb:.4f}\")\n",
    "except:\n",
    "    print(f\"  • AUC-ROC: Not applicable for multiclass\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(f\"\\n📈 Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_xgb))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm_xgb = confusion_matrix(y_test, y_test_pred_xgb)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Greens', cbar=True)\n",
    "plt.title('XGBoost - Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': X_balanced.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n🔍 Top 10 Feature Importances (XGBoost):\")\n",
    "for idx, row in feature_importance_xgb.head(10).iterrows():\n",
    "    print(f\"  • {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# Store test results\n",
    "xgb_test_results = {\n",
    "    'model_name': 'XGBoost',\n",
    "    'test_accuracy': test_accuracy_xgb,\n",
    "    'train_accuracy': trained_models['xgboost']['train_accuracy'],\n",
    "    'cv_score': trained_models['xgboost']['best_score'],\n",
    "    'classification_report': test_report_xgb,\n",
    "    'confusion_matrix': cm_xgb,\n",
    "    'predictions': y_test_pred_xgb,\n",
    "    'probabilities': y_test_proba_xgb,\n",
    "    'feature_importance': feature_importance_xgb\n",
    "}\n",
    "\n",
    "# Calculate overfitting indicator\n",
    "overfitting_xgb = trained_models['xgboost']['train_accuracy'] - test_accuracy_xgb\n",
    "print(f\"\\n🎯 Model Performance Analysis:\")\n",
    "print(f\"  • Overfitting Indicator: {overfitting_xgb:.4f}\")\n",
    "if overfitting_xgb > 0.05:\n",
    "    print(f\"  ⚠️ Potential overfitting detected (train - test > 0.05)\")\n",
    "else:\n",
    "    print(f\"  ✅ Good generalization (minimal overfitting)\")\n",
    "\n",
    "print(\"✅ XGBoost testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efdaf8",
   "metadata": {},
   "source": [
    "### 6.3 Test Random Forest Model\n",
    "\n",
    "Finally, we'll test our optimized Random Forest model and complete the testing phase for all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d50432",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧪 STEP 6.3: TESTING RANDOM FOREST MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test Random Forest model\n",
    "rf_model = trained_models['random_forest']['model']\n",
    "\n",
    "print(f\"📋 Best Random Forest Parameters:\")\n",
    "for param, value in trained_models['random_forest']['best_params'].items():\n",
    "    print(f\"  • {param}: {value}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "print(f\"\\n🔮 Making predictions on test set...\")\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "y_test_proba_rf = rf_model.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "test_report_rf = classification_report(y_test, y_test_pred_rf, output_dict=True)\n",
    "\n",
    "print(f\"\\n📊 Random Forest Test Results:\")\n",
    "print(f\"  • Test Accuracy: {test_accuracy_rf:.4f}\")\n",
    "print(f\"  • Training Accuracy: {trained_models['random_forest']['train_accuracy']:.4f}\")\n",
    "print(f\"  • CV Score: {trained_models['random_forest']['best_score']:.4f}\")\n",
    "\n",
    "# Calculate AUC-ROC if binary classification\n",
    "try:\n",
    "    auc_score_rf = roc_auc_score(y_test, y_test_proba_rf)\n",
    "    print(f\"  • AUC-ROC Score: {auc_score_rf:.4f}\")\n",
    "except:\n",
    "    print(f\"  • AUC-ROC: Not applicable for multiclass\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(f\"\\n📈 Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_rf))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_test_pred_rf)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Oranges', cbar=True)\n",
    "plt.title('Random Forest - Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'feature': X_balanced.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n🔍 Top 10 Feature Importances (Random Forest):\")\n",
    "for idx, row in feature_importance_rf.head(10).iterrows():\n",
    "    print(f\"  • {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# Store test results\n",
    "rf_test_results = {\n",
    "    'model_name': 'Random Forest',\n",
    "    'test_accuracy': test_accuracy_rf,\n",
    "    'train_accuracy': trained_models['random_forest']['train_accuracy'],\n",
    "    'cv_score': trained_models['random_forest']['best_score'],\n",
    "    'classification_report': test_report_rf,\n",
    "    'confusion_matrix': cm_rf,\n",
    "    'predictions': y_test_pred_rf,\n",
    "    'probabilities': y_test_proba_rf,\n",
    "    'feature_importance': feature_importance_rf\n",
    "}\n",
    "\n",
    "# Calculate overfitting indicator\n",
    "overfitting_rf = trained_models['random_forest']['train_accuracy'] - test_accuracy_rf\n",
    "print(f\"\\n🎯 Model Performance Analysis:\")\n",
    "print(f\"  • Overfitting Indicator: {overfitting_rf:.4f}\")\n",
    "if overfitting_rf > 0.05:\n",
    "    print(f\"  ⚠️ Potential overfitting detected (train - test > 0.05)\")\n",
    "else:\n",
    "    print(f\"  ✅ Good generalization (minimal overfitting)\")\n",
    "\n",
    "print(\"✅ Random Forest testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9934729",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 STEP 6 SUMMARY: COMPREHENSIVE MODEL TESTING COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compile all test results\n",
    "all_test_results = {\n",
    "    'Logistic Regression': lr_test_results,\n",
    "    'XGBoost': xgb_test_results,\n",
    "    'Random Forest': rf_test_results\n",
    "}\n",
    "\n",
    "print(\"🏆 Comprehensive Model Performance Comparison:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Model':<18} {'Test Acc':<10} {'Train Acc':<11} {'CV Score':<10} {'Overfitting':<12} {'Generalization':<15}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "best_test_model = \"\"\n",
    "best_test_accuracy = 0\n",
    "\n",
    "for model_name, results in all_test_results.items():\n",
    "    test_acc = results['test_accuracy']\n",
    "    train_acc = results['train_accuracy']\n",
    "    cv_score = results['cv_score']\n",
    "    overfitting = train_acc - test_acc\n",
    "    \n",
    "    # Determine generalization quality\n",
    "    if overfitting < 0.02:\n",
    "        generalization = \"Excellent\"\n",
    "    elif overfitting < 0.05:\n",
    "        generalization = \"Good\"\n",
    "    elif overfitting < 0.10:\n",
    "        generalization = \"Fair\"\n",
    "    else:\n",
    "        generalization = \"Poor\"\n",
    "    \n",
    "    print(f\"{model_name:<18} {test_acc:<10.4f} {train_acc:<11.4f} {cv_score:<10.4f} {overfitting:<12.4f} {generalization:<15}\")\n",
    "    \n",
    "    if test_acc > best_test_accuracy:\n",
    "        best_test_accuracy = test_acc\n",
    "        best_test_model = model_name\n",
    "\n",
    "print(\"-\" * 95)\n",
    "print(f\"🥇 Best performing model on test data: {best_test_model} ({best_test_accuracy:.4f})\")\n",
    "\n",
    "# Performance Analysis\n",
    "print(f\"\\n🎯 Model Analysis Summary:\")\n",
    "print(f\"  ✅ All three models tested on unseen data\")\n",
    "print(f\"  ✅ Confusion matrices generated for error analysis\")\n",
    "print(f\"  ✅ Feature importance calculated for tree-based models\")\n",
    "print(f\"  ✅ Overfitting indicators computed for all models\")\n",
    "\n",
    "# Detailed comparison by metrics\n",
    "print(f\"\\n📈 Detailed Performance Metrics:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Metric':<25} {'LR':<10} {'XGB':<10} {'RF':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Extract metrics for comparison\n",
    "lr_metrics = lr_test_results['classification_report']['weighted avg']\n",
    "xgb_metrics = xgb_test_results['classification_report']['weighted avg']\n",
    "rf_metrics = rf_test_results['classification_report']['weighted avg']\n",
    "\n",
    "print(f\"{'Precision':<25} {lr_metrics['precision']:<10.4f} {xgb_metrics['precision']:<10.4f} {rf_metrics['precision']:<10.4f}\")\n",
    "print(f\"{'Recall':<25} {lr_metrics['recall']:<10.4f} {xgb_metrics['recall']:<10.4f} {rf_metrics['recall']:<10.4f}\")\n",
    "print(f\"{'F1-Score':<25} {lr_metrics['f1-score']:<10.4f} {xgb_metrics['f1-score']:<10.4f} {rf_metrics['f1-score']:<10.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Save all test results for validation phase\n",
    "final_test_results = {\n",
    "    'all_results': all_test_results,\n",
    "    'best_test_model': best_test_model,\n",
    "    'best_test_accuracy': best_test_accuracy,\n",
    "    'performance_summary': {\n",
    "        'logistic_regression': {\n",
    "            'test_accuracy': lr_test_results['test_accuracy'],\n",
    "            'overfitting': lr_test_results['train_accuracy'] - lr_test_results['test_accuracy']\n",
    "        },\n",
    "        'xgboost': {\n",
    "            'test_accuracy': xgb_test_results['test_accuracy'],\n",
    "            'overfitting': xgb_test_results['train_accuracy'] - xgb_test_results['test_accuracy']\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'test_accuracy': rf_test_results['test_accuracy'],\n",
    "            'overfitting': rf_test_results['train_accuracy'] - rf_test_results['test_accuracy']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"🚀 Ready for Step 7: Model Validation and Evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393de93f",
   "metadata": {},
   "source": [
    "## Step 7: Model Validation and Evaluation\n",
    "\n",
    "In this final step, we will conduct comprehensive validation and evaluation of our three trained models. This includes advanced evaluation techniques, model interpretation, and final recommendations.\n",
    "\n",
    "The validation process consists of three detailed analyses:\n",
    "\n",
    "1. **Logistic Regression Model Validation and Evaluation**\n",
    "2. **XGBoost Model Validation and Evaluation**  \n",
    "3. **Random Forest Model Validation and Evaluation**\n",
    "\n",
    "For each model, we will perform:\n",
    "- **ROC Curve Analysis**: Evaluate model discrimination ability\n",
    "- **Precision-Recall Curves**: Assess performance across different thresholds\n",
    "- **Learning Curves**: Analyze training behavior and overfitting\n",
    "- **Cross-Validation Stability**: Ensure consistent performance\n",
    "- **Feature Importance Analysis**: Understand model decision-making\n",
    "- **Model Interpretability**: Extract actionable insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437c5f5",
   "metadata": {},
   "source": [
    "### 7.1 Logistic Regression Model Validation and Evaluation\n",
    "\n",
    "We'll perform comprehensive validation of our Logistic Regression model, focusing on interpretability and performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 STEP 7.1: LOGISTIC REGRESSION MODEL VALIDATION & EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the Logistic Regression model and results\n",
    "lr_model = trained_models['logistic_regression']['model']\n",
    "lr_results = all_test_results['Logistic Regression']\n",
    "\n",
    "print(\"📊 Advanced Evaluation for Logistic Regression Model\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# 1. ROC Curve Analysis\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, lr_results['probabilities'])\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "# 2. Precision-Recall Curve\n",
    "precision_lr, recall_lr, pr_thresholds_lr = precision_recall_curve(y_test, lr_results['probabilities'])\n",
    "pr_auc_lr = auc(recall_lr, precision_lr)\n",
    "\n",
    "# 3. Plot ROC and PR Curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# ROC Curve\n",
    "ax1.plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc_lr:.3f})')\n",
    "ax1.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', alpha=0.7)\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('Logistic Regression - ROC Curve')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "ax2.plot(recall_lr, precision_lr, color='green', lw=2, label=f'PR Curve (AUC = {pr_auc_lr:.3f})')\n",
    "ax2.set_xlim([0.0, 1.0])\n",
    "ax2.set_ylim([0.0, 1.05])\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Logistic Regression - Precision-Recall Curve')\n",
    "ax2.legend(loc=\"lower left\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Feature Coefficient Analysis (Interpretability)\n",
    "feature_coefficients = pd.DataFrame({\n",
    "    'feature': X_balanced.columns,\n",
    "    'coefficient': lr_model.coef_[0],\n",
    "    'abs_coefficient': np.abs(lr_model.coef_[0])\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\n🔍 Top 10 Most Important Features (by coefficient magnitude):\")\n",
    "for idx, row in feature_coefficients.head(10).iterrows():\n",
    "    direction = \"↑ Increases\" if row['coefficient'] > 0 else \"↓ Decreases\"\n",
    "    print(f\"  • {row['feature']}: {row['coefficient']:.4f} ({direction} risk)\")\n",
    "\n",
    "# 5. Learning Curves\n",
    "print(f\"\\n📈 Generating Learning Curves...\")\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    lr_model, X_balanced, y_balanced, cv=5, n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy'\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot Learning Curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Accuracy')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='red', label='Validation Accuracy')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2, color='red')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Logistic Regression - Learning Curves')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6. Cross-Validation Stability Analysis\n",
    "cv_scores = trained_models['logistic_regression']['grid_search'].cv_results_['split0_test_score'][:5]  # First 5 folds\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "\n",
    "print(f\"\\n🎯 Model Validation Summary:\")\n",
    "print(f\"  • ROC-AUC Score: {roc_auc_lr:.4f}\")\n",
    "print(f\"  • Precision-Recall AUC: {pr_auc_lr:.4f}\")\n",
    "print(f\"  • CV Stability (std): {cv_std:.4f}\")\n",
    "print(f\"  • Final Training Size Performance: {val_mean[-1]:.4f} ± {val_std[-1]:.4f}\")\n",
    "\n",
    "# 7. Model Interpretation Summary\n",
    "print(f\"\\n💡 Logistic Regression Insights:\")\n",
    "print(f\"  ✅ Most Predictive Feature: {feature_coefficients.iloc[0]['feature']}\")\n",
    "print(f\"  ✅ Coefficient Range: {feature_coefficients['coefficient'].min():.3f} to {feature_coefficients['coefficient'].max():.3f}\")\n",
    "print(f\"  ✅ Model Complexity: Linear decision boundary\")\n",
    "print(f\"  ✅ Interpretability: High (coefficients show feature impact)\")\n",
    "\n",
    "# Store validation results\n",
    "lr_validation_results = {\n",
    "    'roc_auc': roc_auc_lr,\n",
    "    'pr_auc': pr_auc_lr,\n",
    "    'cv_stability': cv_std,\n",
    "    'feature_coefficients': feature_coefficients,\n",
    "    'learning_curve_final': val_mean[-1],\n",
    "    'model_complexity': 'Linear'\n",
    "}\n",
    "\n",
    "print(\"✅ Logistic Regression validation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c4e6d",
   "metadata": {},
   "source": [
    "### 7.2 XGBoost Model Validation and Evaluation\n",
    "\n",
    "Now we'll perform comprehensive validation of our XGBoost model, focusing on ensemble performance and feature importance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef02687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 STEP 7.2: XGBOOST MODEL VALIDATION & EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get the XGBoost model and results\n",
    "xgb_model = trained_models['xgboost']['model']\n",
    "xgb_results = all_test_results['XGBoost']\n",
    "\n",
    "print(\"📊 Advanced Evaluation for XGBoost Model\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 1. ROC Curve Analysis\n",
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_test, xgb_results['probabilities'])\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "\n",
    "# 2. Precision-Recall Curve\n",
    "precision_xgb, recall_xgb, pr_thresholds_xgb = precision_recall_curve(y_test, xgb_results['probabilities'])\n",
    "pr_auc_xgb = auc(recall_xgb, precision_xgb)\n",
    "\n",
    "# 3. Plot ROC and PR Curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# ROC Curve\n",
    "ax1.plot(fpr_xgb, tpr_xgb, color='green', lw=2, label=f'ROC Curve (AUC = {roc_auc_xgb:.3f})')\n",
    "ax1.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', alpha=0.7)\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('XGBoost - ROC Curve')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "ax2.plot(recall_xgb, precision_xgb, color='orange', lw=2, label=f'PR Curve (AUC = {pr_auc_xgb:.3f})')\n",
    "ax2.set_xlim([0.0, 1.0])\n",
    "ax2.set_ylim([0.0, 1.05])\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('XGBoost - Precision-Recall Curve')\n",
    "ax2.legend(loc=\"lower left\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Feature Importance Analysis (already computed in testing phase)\n",
    "feature_importance_xgb = xgb_results['feature_importance']\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance_xgb.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='darkgreen', alpha=0.7)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('XGBoost - Top 15 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🔍 Top 10 Most Important Features (XGBoost):\")\n",
    "for idx, row in feature_importance_xgb.head(10).iterrows():\n",
    "    print(f\"  • {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# 5. Learning Curves for XGBoost\n",
    "print(f\"\\n📈 Generating Learning Curves...\")\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    xgb_model, X_balanced, y_balanced, cv=5, n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy'\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot Learning Curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='darkgreen', label='Training Accuracy')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='darkgreen')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='orange', label='Validation Accuracy')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2, color='orange')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('XGBoost - Learning Curves')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6. Model Complexity Analysis\n",
    "n_estimators = xgb_model.get_params()['n_estimators']\n",
    "max_depth = xgb_model.get_params()['max_depth']\n",
    "learning_rate = xgb_model.get_params()['learning_rate']\n",
    "\n",
    "print(f\"\\n🔧 XGBoost Model Configuration:\")\n",
    "print(f\"  • Number of Trees: {n_estimators}\")\n",
    "print(f\"  • Maximum Depth: {max_depth}\")\n",
    "print(f\"  • Learning Rate: {learning_rate}\")\n",
    "print(f\"  • Subsample: {xgb_model.get_params()['subsample']}\")\n",
    "print(f\"  • Column Sample: {xgb_model.get_params()['colsample_bytree']}\")\n",
    "\n",
    "# 7. Cross-Validation Stability\n",
    "cv_scores = trained_models['xgboost']['grid_search'].cv_results_['split0_test_score'][:5]\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "\n",
    "print(f\"\\n🎯 XGBoost Validation Summary:\")\n",
    "print(f\"  • ROC-AUC Score: {roc_auc_xgb:.4f}\")\n",
    "print(f\"  • Precision-Recall AUC: {pr_auc_xgb:.4f}\")\n",
    "print(f\"  • CV Stability (std): {cv_std:.4f}\")\n",
    "print(f\"  • Final Training Size Performance: {val_mean[-1]:.4f} ± {val_std[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\n💡 XGBoost Model Insights:\")\n",
    "print(f\"  ✅ Most Predictive Feature: {feature_importance_xgb.iloc[0]['feature']}\")\n",
    "print(f\"  ✅ Feature Importance Range: {feature_importance_xgb['importance'].min():.3f} to {feature_importance_xgb['importance'].max():.3f}\")\n",
    "print(f\"  ✅ Model Complexity: Ensemble of {n_estimators} trees\")\n",
    "print(f\"  ✅ Interpretability: Medium (tree-based feature importance)\")\n",
    "\n",
    "# Store validation results\n",
    "xgb_validation_results = {\n",
    "    'roc_auc': roc_auc_xgb,\n",
    "    'pr_auc': pr_auc_xgb,\n",
    "    'cv_stability': cv_std,\n",
    "    'feature_importance': feature_importance_xgb,\n",
    "    'learning_curve_final': val_mean[-1],\n",
    "    'model_complexity': f'Ensemble of {n_estimators} trees',\n",
    "    'top_feature': feature_importance_xgb.iloc[0]['feature']\n",
    "}\n",
    "\n",
    "print(\"✅ XGBoost validation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60fdd7",
   "metadata": {},
   "source": [
    "### 7.3 Random Forest Model Validation and Evaluation\n",
    "\n",
    "Finally, we'll perform comprehensive validation of our Random Forest model, focusing on ensemble robustness and out-of-bag performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 STEP 7.3: RANDOM FOREST MODEL VALIDATION & EVALUATION\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Get the Random Forest model and results\n",
    "rf_model = trained_models['random_forest']['model']\n",
    "rf_results = all_test_results['Random Forest']\n",
    "\n",
    "print(\"📊 Advanced Evaluation for Random Forest Model\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# 1. ROC Curve Analysis\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, rf_results['probabilities'])\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# 2. Precision-Recall Curve\n",
    "precision_rf, recall_rf, pr_thresholds_rf = precision_recall_curve(y_test, rf_results['probabilities'])\n",
    "pr_auc_rf = auc(recall_rf, precision_rf)\n",
    "\n",
    "# 3. Plot ROC and PR Curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# ROC Curve\n",
    "ax1.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc_rf:.3f})')\n",
    "ax1.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', alpha=0.7)\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('Random Forest - ROC Curve')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "ax2.plot(recall_rf, precision_rf, color='purple', lw=2, label=f'PR Curve (AUC = {pr_auc_rf:.3f})')\n",
    "ax2.set_xlim([0.0, 1.0])\n",
    "ax2.set_ylim([0.0, 1.05])\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Random Forest - Precision-Recall Curve')\n",
    "ax2.legend(loc=\"lower left\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Feature Importance Analysis (already computed in testing phase)\n",
    "feature_importance_rf = rf_results['feature_importance']\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance_rf.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='darkorange', alpha=0.7)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest - Top 15 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n🔍 Top 10 Most Important Features (Random Forest):\")\n",
    "for idx, row in feature_importance_rf.head(10).iterrows():\n",
    "    print(f\"  • {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# 5. Learning Curves for Random Forest\n",
    "print(f\"\\n📈 Generating Learning Curves...\")\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    rf_model, X_balanced, y_balanced, cv=5, n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy'\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot Learning Curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='darkorange', label='Training Accuracy')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='darkorange')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='purple', label='Validation Accuracy')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2, color='purple')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Random Forest - Learning Curves')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6. Out-of-Bag (OOB) Score Analysis (if available)\n",
    "try:\n",
    "    # Create a new Random Forest with OOB scoring enabled\n",
    "    rf_oob = RandomForestClassifier(\n",
    "        **rf_model.get_params(),\n",
    "        oob_score=True\n",
    "    )\n",
    "    rf_oob.fit(X_balanced, y_balanced)\n",
    "    oob_score = rf_oob.oob_score_\n",
    "    print(f\"\\n📊 Out-of-Bag Score: {oob_score:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️ OOB score not available: {str(e)}\")\n",
    "    oob_score = None\n",
    "\n",
    "# 7. Model Complexity Analysis\n",
    "n_estimators = rf_model.get_params()['n_estimators']\n",
    "max_depth = rf_model.get_params()['max_depth']\n",
    "min_samples_split = rf_model.get_params()['min_samples_split']\n",
    "min_samples_leaf = rf_model.get_params()['min_samples_leaf']\n",
    "\n",
    "print(f\"\\n🔧 Random Forest Model Configuration:\")\n",
    "print(f\"  • Number of Trees: {n_estimators}\")\n",
    "print(f\"  • Maximum Depth: {max_depth}\")\n",
    "print(f\"  • Min Samples Split: {min_samples_split}\")\n",
    "print(f\"  • Min Samples Leaf: {min_samples_leaf}\")\n",
    "print(f\"  • Max Features: {rf_model.get_params()['max_features']}\")\n",
    "\n",
    "# 8. Cross-Validation Stability\n",
    "cv_scores = trained_models['random_forest']['grid_search'].cv_results_['split0_test_score'][:5]\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "\n",
    "print(f\"\\n🎯 Random Forest Validation Summary:\")\n",
    "print(f\"  • ROC-AUC Score: {roc_auc_rf:.4f}\")\n",
    "print(f\"  • Precision-Recall AUC: {pr_auc_rf:.4f}\")\n",
    "if oob_score:\n",
    "    print(f\"  • Out-of-Bag Score: {oob_score:.4f}\")\n",
    "print(f\"  • CV Stability (std): {cv_std:.4f}\")\n",
    "print(f\"  • Final Training Size Performance: {val_mean[-1]:.4f} ± {val_std[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\n💡 Random Forest Model Insights:\")\n",
    "print(f\"  ✅ Most Predictive Feature: {feature_importance_rf.iloc[0]['feature']}\")\n",
    "print(f\"  ✅ Feature Importance Range: {feature_importance_rf['importance'].min():.3f} to {feature_importance_rf['importance'].max():.3f}\")\n",
    "print(f\"  ✅ Model Complexity: Ensemble of {n_estimators} independent trees\")\n",
    "print(f\"  ✅ Interpretability: Medium (tree-based feature importance)\")\n",
    "print(f\"  ✅ Robustness: High (bootstrap aggregation reduces overfitting)\")\n",
    "\n",
    "# Store validation results\n",
    "rf_validation_results = {\n",
    "    'roc_auc': roc_auc_rf,\n",
    "    'pr_auc': pr_auc_rf,\n",
    "    'oob_score': oob_score,\n",
    "    'cv_stability': cv_std,\n",
    "    'feature_importance': feature_importance_rf,\n",
    "    'learning_curve_final': val_mean[-1],\n",
    "    'model_complexity': f'Ensemble of {n_estimators} independent trees',\n",
    "    'top_feature': feature_importance_rf.iloc[0]['feature']\n",
    "}\n",
    "\n",
    "print(\"✅ Random Forest validation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7cb9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🏆 STEP 7 FINAL: COMPREHENSIVE MODEL COMPARISON & CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compile all validation results\n",
    "all_validation_results = {\n",
    "    'Logistic Regression': lr_validation_results,\n",
    "    'XGBoost': xgb_validation_results,\n",
    "    'Random Forest': rf_validation_results\n",
    "}\n",
    "\n",
    "print(\"📊 FINAL MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'Model':<18} {'Test Acc':<10} {'ROC-AUC':<10} {'PR-AUC':<10} {'CV Std':<10} {'Complexity':<20}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "best_overall_model = \"\"\n",
    "best_overall_score = 0\n",
    "\n",
    "for model_name in ['Logistic Regression', 'XGBoost', 'Random Forest']:\n",
    "    test_results = all_test_results[model_name]\n",
    "    val_results = all_validation_results[model_name]\n",
    "    \n",
    "    test_acc = test_results['test_accuracy']\n",
    "    roc_auc = val_results['roc_auc']\n",
    "    pr_auc = val_results['pr_auc']\n",
    "    cv_std = val_results['cv_stability']\n",
    "    complexity = val_results['model_complexity']\n",
    "    \n",
    "    # Composite score (test accuracy + ROC-AUC + stability bonus)\n",
    "    stability_bonus = max(0, (0.02 - cv_std) * 2)  # Bonus for stability\n",
    "    composite_score = (test_acc + roc_auc) / 2 + stability_bonus\n",
    "    \n",
    "    print(f\"{model_name:<18} {test_acc:<10.4f} {roc_auc:<10.4f} {pr_auc:<10.4f} {cv_std:<10.4f} {complexity:<20}\")\n",
    "    \n",
    "    if composite_score > best_overall_score:\n",
    "        best_overall_score = composite_score\n",
    "        best_overall_model = model_name\n",
    "\n",
    "print(\"-\" * 100)\n",
    "print(f\"🥇 RECOMMENDED MODEL: {best_overall_model}\")\n",
    "\n",
    "# Feature Importance Comparison\n",
    "print(f\"\\n🔍 TOP FEATURE COMPARISON ACROSS MODELS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "if 'feature_coefficients' in lr_validation_results:\n",
    "    lr_top = lr_validation_results['feature_coefficients'].iloc[0]['feature']\n",
    "else:\n",
    "    lr_top = \"N/A\"\n",
    "\n",
    "xgb_top = xgb_validation_results['top_feature']\n",
    "rf_top = rf_validation_results['top_feature']\n",
    "\n",
    "print(f\"{'Model':<20} {'Most Important Feature':<30} {'Importance Type':<20}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Logistic Regression':<20} {lr_top:<30} {'Coefficient':<20}\")\n",
    "print(f\"{'XGBoost':<20} {xgb_top:<30} {'Gain':<20}\")\n",
    "print(f\"{'Random Forest':<20} {rf_top:<30} {'Gini Importance':<20}\")\n",
    "\n",
    "# ROC Curve Comparison\n",
    "print(f\"\\n📈 GENERATING COMPREHENSIVE ROC COMPARISON...\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'Logistic Regression (AUC = {roc_auc_lr:.3f})')\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='green', lw=2, label=f'XGBoost (AUC = {roc_auc_xgb:.3f})')\n",
    "plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label=f'Random Forest (AUC = {roc_auc_rf:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', alpha=0.7, label='Random Classifier')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve Comparison - All Models', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Model Recommendations\n",
    "print(f\"\\n💡 MODEL SELECTION RECOMMENDATIONS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Analyze each model's strengths\n",
    "models_analysis = {\n",
    "    'Logistic Regression': {\n",
    "        'strengths': ['High interpretability', 'Fast training/prediction', 'Stable performance'],\n",
    "        'weaknesses': ['Linear decision boundary', 'May underfit complex patterns'],\n",
    "        'use_case': 'Medical diagnosis with interpretability requirements'\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'strengths': ['Excellent performance', 'Handles missing values', 'Built-in regularization'],\n",
    "        'weaknesses': ['Complex hyperparameter tuning', 'Longer training time'],\n",
    "        'use_case': 'High-accuracy prediction with moderate interpretability'\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'strengths': ['Robust to overfitting', 'Good default performance', 'Feature importance'],\n",
    "        'weaknesses': ['Can overfit with noisy data', 'Less interpretable than logistic regression'],\n",
    "        'use_case': 'General-purpose classification with feature importance analysis'\n",
    "    }\n",
    "}\n",
    "\n",
    "for model_name, analysis in models_analysis.items():\n",
    "    test_acc = all_test_results[model_name]['test_accuracy']\n",
    "    print(f\"\\n🔍 {model_name.upper()} ANALYSIS (Test Accuracy: {test_acc:.4f})\")\n",
    "    print(f\"  ✅ Strengths: {', '.join(analysis['strengths'])}\")\n",
    "    print(f\"  ⚠️ Considerations: {', '.join(analysis['weaknesses'])}\")\n",
    "    print(f\"  🎯 Best Use Case: {analysis['use_case']}\")\n",
    "\n",
    "# Final Business Recommendations\n",
    "print(f\"\\n🎯 BUSINESS RECOMMENDATIONS:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"1. 🏥 For Medical Diagnosis Deployment:\")\n",
    "print(f\"   Recommended: Logistic Regression\")\n",
    "print(f\"   Reason: High interpretability for medical decisions\")\n",
    "print(f\"   \n",
    "print(f\"2. 🔬 For Research and Analysis:\")\n",
    "print(f\"   Recommended: {best_overall_model}\")\n",
    "print(f\"   Reason: Best overall performance and validation metrics\")\n",
    "\n",
    "print(f\"3. 🚀 For Production Systems:\")\n",
    "print(f\"   Recommended: XGBoost or Random Forest\")\n",
    "print(f\"   Reason: Robust performance with good generalization\")\n",
    "\n",
    "print(f\"4. 📊 For Feature Analysis:\")\n",
    "print(f\"   Recommended: Random Forest\")\n",
    "print(f\"   Reason: Reliable feature importance rankings\")\n",
    "\n",
    "# Summary Statistics\n",
    "print(f\"\\n📈 PROJECT SUMMARY STATISTICS:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"  • Models Trained: 3\")\n",
    "print(f\"  • Best Test Accuracy: {max([r['test_accuracy'] for r in all_test_results.values()]):.4f}\")\n",
    "print(f\"  • Best ROC-AUC: {max([r['roc_auc'] for r in all_validation_results.values()]):.4f}\")\n",
    "print(f\"  • Most Stable Model: {min(all_validation_results.keys(), key=lambda k: all_validation_results[k]['cv_stability'])}\")\n",
    "print(f\"  • Training Data Size: {len(X_balanced):,} samples\")\n",
    "print(f\"  • Test Data Size: {len(X_test):,} samples\")\n",
    "print(f\"  • Feature Count: {len(X_balanced.columns)}\")\n",
    "\n",
    "print(f\"\\n🎉 MACHINE LEARNING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"✅ All models trained, tested, and validated\")\n",
    "print(\"✅ Comprehensive performance analysis completed\")\n",
    "print(\"✅ Business recommendations provided\")\n",
    "print(\"✅ Ready for deployment and production use!\")\n",
    "\n",
    "# Save final results summary\n",
    "final_project_summary = {\n",
    "    'best_model': best_overall_model,\n",
    "    'best_test_accuracy': max([r['test_accuracy'] for r in all_test_results.values()]),\n",
    "    'best_roc_auc': max([r['roc_auc'] for r in all_validation_results.values()]),\n",
    "    'model_performances': {\n",
    "        model: {\n",
    "            'test_accuracy': all_test_results[model]['test_accuracy'],\n",
    "            'roc_auc': all_validation_results[model]['roc_auc'],\n",
    "            'stability': all_validation_results[model]['cv_stability']\n",
    "        }\n",
    "        for model in all_test_results.keys()\n",
    "    },\n",
    "    'recommendations': models_analysis\n",
    "}\n",
    "\n",
    "print(f\"📁 Final results saved to final_project_summary dictionary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
